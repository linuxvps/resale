import logging
import os
from datetime import datetime

import numpy as np
import pandas as pd
from colorlog import ColoredFormatter
# ------------------------------------------------------------
# Ø¨Ø®Ø´ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ SQLAlchemy Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ ØªØ¹Ø±ÛŒÙ Ø§Ù†ØªÛŒØªÛŒ
# ------------------------------------------------------------
from sqlalchemy import create_engine, Column, Integer, BigInteger, String, Date, DateTime, Numeric, Float
from sqlalchemy.orm import declarative_base, sessionmaker

Base = declarative_base()
protected_columns = ['approval_amount', 'interest_amount']

formatter = ColoredFormatter(
    "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
    datefmt=None,
    reset=True,
    log_colors={
        'DEBUG': 'cyan',
        'INFO': 'white',
        'WARNING': 'yellow',
        'ERROR': 'red',
        'CRITICAL': 'bold_red',
    }
)

handler = logging.StreamHandler()
handler.setFormatter(formatter)

logger = logging.getLogger()
logger.addHandler(handler)
logger.setLevel(logging.INFO)


class ParsianLoan(Base):
    __tablename__ = "parsian_loan"

    # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ù…Ø·Ø§Ø¨Ù‚ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ parsian_loan
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    insert_sysdate = Column(DateTime, nullable=False, default=datetime.utcnow)
    branch_code = Column(Integer, nullable=False)
    branchname = Column(String(100), nullable=True)
    client_id = Column(Integer, nullable=True)
    loan_file_numberr = Column(BigInteger, nullable=True)
    sit_flag = Column(String(1), nullable=True)
    interest_rate = Column(Numeric(19, 2), nullable=True)
    total_repayment_up_to_now = Column(Numeric(28, 8), nullable=True)
    commission_amount_remain = Column(Numeric(28, 8), nullable=True)
    charge = Column(Numeric(28, 8), nullable=True)
    discount = Column(Numeric(28, 8), nullable=True)
    advance_pay_to_total_cash = Column(Numeric(28, 8), nullable=True)
    advance_pay_to_remain_non_cash = Column(Numeric(28, 8), nullable=True)
    is_installment = Column(String(1), nullable=True)
    interest_sum = Column(Numeric(28, 8), nullable=True)
    installment_number_remain = Column(Integer, nullable=True)
    receivable_installment_number = Column(Integer, nullable=True)
    first_passed = Column(Date, nullable=True)
    total_payment_up_to_now = Column(Numeric(28, 8), nullable=True)
    finalized_loan_amount = Column(Numeric(28, 8), nullable=True)
    penalty = Column(Numeric(28, 8), nullable=True)
    first_payment_date_in_du = Column(Date, nullable=True)
    principal_sum = Column(Numeric(28, 8), nullable=True)
    advance_pay = Column(Numeric(28, 8), nullable=True)
    sit_duration = Column(Integer, nullable=True)
    sit_duration_day = Column(Integer, nullable=True)
    sit_distribute_phases = Column(Integer, nullable=True)
    sit_fast_receive_percent = Column(Float, nullable=True)
    frequency = Column(Integer, nullable=True)
    customer_obligation_amount = Column(Numeric(28, 8), nullable=True)
    customer_share_cash_amount = Column(Numeric(28, 8), nullable=True)
    customer_share_non_cash_amount = Column(Numeric(28, 8), nullable=True)
    bank_share_cash_amount = Column(Numeric(28, 8), nullable=True)
    bank_share_non_cash_amount = Column(Numeric(28, 8), nullable=True)
    first_over_due = Column(Date, nullable=True)
    loan_duration_day = Column(Integer, nullable=True)
    loan_file_number = Column(BigInteger, nullable=True)
    create_date = Column(Date, nullable=True)
    long_title = Column(String(255), nullable=True)
    status = Column(String(255), nullable=True)
    contract = Column(String(255), nullable=True)
    approval_amount = Column(Numeric(28, 8), nullable=True)
    title = Column(String(255), nullable=True)
    inc_commission_amount = Column(Numeric(28, 8), nullable=True)
    interest_amount = Column(Numeric(28, 8), nullable=True)
    obligation_penalty = Column(Numeric(28, 8), nullable=True)
    passed_date = Column(Date, nullable=True)
    penalty_interest = Column(Numeric(28, 8), nullable=True)
    to_due_date = Column(Numeric(28, 8), nullable=True)
    to_end_of_month = Column(Numeric(28, 8), nullable=True)
    due_date = Column(Date, nullable=True)

    def __repr__(self):
        return f"<ParsianLoan(id={self.id}, branch_code={self.branch_code}, client_id={self.client_id})>"


class LoanRepository:
    """
    Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ parsian_loan Ø¨Ø§ SQLAlchemy.
    """

    def __init__(self):
        # ÙØ±Ø¶ Ú©Ù†ÛŒØ¯ Connection String Ø±Ø§ Ø¯Ø± Ù…ØªØºÛŒØ±Ù…Ø­ÛŒØ·ÛŒ DB_CONNECTION_STRING Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒÙ….
        self.db_conn_str = os.getenv("DB_CONNECTION_STRING", "mysql+pymysql://root:pass@localhost:3306/ln")
        self.engine = create_engine(self.db_conn_str)
        SessionLocal = sessionmaker(bind=self.engine)
        self.session = SessionLocal()

    def fetch_loans(self, limit=10000):
        """
        ÙˆØ§Ú©Ø´ÛŒ Ø­Ø¯Ø§Ú©Ø«Ø± `limit` Ø±Ú©ÙˆØ±Ø¯ Ø§Ø² Ø¬Ø¯ÙˆÙ„ parsian_loan.
        Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ ÛŒÚ© DataFrame Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
        """
        loans = self.session.query(ParsianLoan).limit(limit).all()
        if not loans:
            logging.warning("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return pd.DataFrame()

        columns = [c.name for c in ParsianLoan.__table__.columns]
        data = {}
        for col in columns:
            data[col] = [getattr(loan, col) for loan in loans]
        df = pd.DataFrame(data)
        logging.info(f"âœ… {len(df)} Ø±Ú©ÙˆØ±Ø¯ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ (parsian_loan).")
        return df


###########################################
# Ú¯Ø§Ù… Ø¯ÙˆÙ…: Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ (Default Probability)
###########################################

class ParsianDefaultProbabilityModel:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú¯Ø§Ù… Ø¯ÙˆÙ… Ø¯Ø± pseudocodeorg:
    - Ø¢Ù…ÙˆØ²Ø´ ÛŒÚ© Ù…Ø¯Ù„ (Ù…Ø«Ù„Ø§Ù‹ LightGBM) Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
    - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†
    """

    def __init__(
        self,
        model_type="lightgbm",
        n_estimators=100,
        learning_rate=0.05,
        random_state=42,
        **kwargs
    ):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - model_type: Ù†ÙˆØ¹ Ù…Ø¯Ù„ (lightgbm, xgboost ÛŒØ§ Ù‡Ø± Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ)
          - n_estimators, learning_rate: Ù‡Ø§ÛŒÙ¾Ø±Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
          - random_state: Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ØªÙˆÙ„ÛŒØ¯ Ù¾Ø°ÛŒØ±ÛŒ
          - kwargs: Ø³Ø§ÛŒØ± Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡ Ù…Ø¯Ù„
        """

        self.model_type = model_type
        self.n_estimators = n_estimators
        self.learning_rate = learning_rate
        self.random_state = random_state
        self.model = None
        self.default_probabilities_ = None  # Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ test

        self.kwargs = kwargs

    def fit_model(self, x_train, y_train):
        """
        Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ:
        Ø¯Ø± Ø§ÛŒÙ† Ù…Ø«Ø§Ù„ØŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ LightGBM Ø§Ø³Øª.
        """
        if self.model_type.lower() == "lightgbm":
            logging.info("ğŸ”µ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LightGBM...")
            self.model = LGBMClassifier(
                n_estimators=self.n_estimators,
                learning_rate=self.learning_rate,
                random_state=self.random_state,
                **self.kwargs
            )
        else:
            raise ValueError("ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ù…Ø¯Ù„ lightgbm Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„).")

        self.model.fit(x_train, y_train)
        logging.info("âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

    def predict_default_probability(self, x_test):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª.
        Ø®Ø±ÙˆØ¬ÛŒ: ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ NumPy Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø­ØªÙ…Ø§Ù„ (Ø¨ÛŒÙ† Û° Ùˆ Û±)
        """
        if not self.model:
            raise ValueError("Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø¯Ù„ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯ (fit_model).")

        logging.info("ğŸ”µ Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†...")
        probs = self.model.predict_proba(x_test)
        # Ú†ÙˆÙ† Ø®Ø±ÙˆØ¬ÛŒ predict_proba Ø¯Ùˆ Ø³ØªÙˆÙ† [Prob_of_Class_0, Prob_of_Class_1] Ø§Ø³ØªØŒ
        # Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø³ØªÙˆÙ† Ø¯ÙˆÙ… (Ú©Ù„Ø§Ø³ Û±) Ø§Ø³Øª.
        self.default_probabilities_ = probs[:, 1]
        return self.default_probabilities_

    def get_model(self):
        """ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø´ÛŒØ¡ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡. """
        return self.model


# ------------------------------------------------------------
# Ú¯Ø§Ù… Ø§ÙˆÙ„: Preprocessing Manager Ùˆ Preprocessor
# ------------------------------------------------------------
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import RFECV
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE


class LoanPreprocessor:
    """
    Ú©Ù„Ø§Ø³ Ù…Ø³Ø¦ÙˆÙ„ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´:
    - ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨ (status) Ø¨Ù‡ Ù†Ú©ÙˆÙ„/ØºÛŒØ±Ù†Ú©ÙˆÙ„ (Û° ÛŒØ§ Û±)
    - ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ ÛŒØ§ Ø²Ù…Ø§Ù†
    - Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
    - Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ú©Ù…Ú© LGBM + RFECV
    - Ø§ÛŒÙ…Ù¾ÛŒÙˆØª Ø¯Ø§Ø¯Ù‡ (SimpleImputer)
    """

    def __init__(self, imputation_strategy="mean"):
        self.imputer = SimpleImputer(strategy=imputation_strategy)

    def convert_labels(self, df, label_column="status"):
        logging.info(f"[LoanPreprocessor] ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨: {label_column}")
        if label_column not in df.columns:
            raise ValueError(f"Ø³ØªÙˆÙ† {label_column} Ø¯Ø± Ø¯Ø§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

        # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± {"Ù…Ø´ÙƒÙˆÙƒ Ø§Ù„ÙˆØµÙˆÙ„", "Ù…Ø¹ÙˆÙ‚", "Ø³Ø±Ø±Ø³ÙŠØ¯ Ú¯Ø°Ø´ØªÙ‡"} => 1
        default_statuses = {"Ù…Ø´ÙƒÙˆÙƒ Ø§Ù„ÙˆØµÙˆÙ„", "Ù…Ø¹ÙˆÙ‚", "Ø³Ø±Ø±Ø³ÙŠØ¯ Ú¯Ø°Ø´ØªÙ‡"}
        df[label_column] = df[label_column].apply(lambda x: 1 if x in default_statuses else 0)
        return df

    def convert_dataframe_columns(self, df):
        """
        ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ timestamp Ùˆ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ object Ø¨Ù‡ numeric.
        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² LabelEncoder Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        """
        for col in df.columns:
            if np.issubdtype(df[col].dtype, np.datetime64):
                df[col] = pd.to_datetime(df[col]).apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan)
            elif df[col].dtype == 'object':
                try:
                    df[col] = pd.to_numeric(df[col])
                except Exception:
                    le = LabelEncoder()
                    df[col] = le.fit_transform(df[col].astype(str))
        return df

    def remove_highly_correlated_features(self, data, threshold=0.9, class_column=None):
        new_data = data.copy()
        numeric_cols = new_data.select_dtypes(include=[np.number]).columns.tolist()
        if class_column and class_column in numeric_cols:
            numeric_cols.remove(class_column)

        protected_columns = ["approval_amount", "interest_amount"]  # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù†Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯
        numeric_cols = [c for c in numeric_cols if c not in protected_columns]

        corr_matrix = new_data[numeric_cols].corr()
        attributes_to_remove = set()
        for i in range(len(numeric_cols) - 1):
            for j in range(i + 1, len(numeric_cols)):
                col_i = numeric_cols[i]
                col_j = numeric_cols[j]
                corr_value = corr_matrix.loc[col_i, col_j]
                if abs(corr_value) > threshold:
                    logging.info(f"Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§: {col_i} - {col_j} => {corr_value:.2f}, Ø­Ø°Ù {col_j}")
                    attributes_to_remove.add(col_j)

        for col_r in attributes_to_remove:
            if col_r in new_data.columns:
                new_data.drop(columns=[col_r], inplace=True)

        return new_data

    def select_features(self, X, y):
        lgbm_estimator = LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42, verbose=-1)
        rfecv = RFECV(estimator=lgbm_estimator, step=1, cv=5, scoring='accuracy', n_jobs=-1, verbose=0)
        rfecv.fit(X, y)
        selected_features = list(X.columns[rfecv.support_])
        for col in protected_columns:
            if col in X.columns and col not in selected_features:
                selected_features.append(col)
        not_selected_features = [col for col in X.columns if col not in selected_features]
        logging.info("ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡: " + ", ".join(selected_features))
        logging.info("ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡: " + ", ".join(not_selected_features))
        return X.loc[:, selected_features]


class ParsianPreprocessingManager:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ Ú¯Ø§Ù… Ø§ÙˆÙ„ (Preprocessing) Ø§Ø² pseudocodeorg.
    """

    def __init__(
            self,
            repository,
            limit_records=10000,
            label_column="status",
            imputation_strategy="mean",
            need_2_remove_highly_correlated_features=False,
            correlation_threshold=0.9,
            do_balance=True,
            test_size=0.2,
            random_state=42
    ):
        self.repository = repository
        self.limit_records = limit_records
        self.label_column = label_column
        self.imputation_strategy = imputation_strategy
        self.correlation_threshold = correlation_threshold
        self.need_2_remove_highly_correlated_features = need_2_remove_highly_correlated_features
        self.do_balance = do_balance
        self.test_size = test_size
        self.random_state = random_state

        self.x_train = None
        self.y_train = None
        self.x_test = None
        self.y_test = None
        self.original_df = None
        self.preprocessor = None

    def step1_process_data(self):
        """
        1) ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² parsian_loan
        2) ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨ Ù†Ú©ÙˆÙ„ => 0/1
        3) ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ† => Ø¹Ø¯Ø¯ÛŒ
        4) Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
        5) Ø§ÛŒÙ…Ù¾ÛŒÙˆØª
        6) ØªÙÚ©ÛŒÚ© X,y
        7) train_test_split
        8) Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ
        9) Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ SMOTE (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)

        Ø®Ø±ÙˆØ¬ÛŒ: (x_train, y_train, x_test, y_test, original_df)
        """
        logging.info("ğŸ”µ [Step1] Ø´Ø±ÙˆØ¹ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Preprocessing).")

        df = self.repository.fetch_loans(limit=self.limit_records)
        if df.empty:
            logging.error("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª.")
            return None, None, None, None, None
        logging.info(f"ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ø¯Ø±ÛŒØ§ÙØªÛŒ: {len(df)}")

        self.preprocessor = LoanPreprocessor(imputation_strategy=self.imputation_strategy)

        # Ø¨Ø±Ú†Ø³Ø¨ Ù†Ú©ÙˆÙ„
        df = self.preprocessor.convert_labels(df, label_column=self.label_column)

        # ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ†
        df = self.preprocessor.convert_dataframe_columns(df)

        # Ù…Ø«Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø¨Ø±Ø®ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        drop_columns = ["create_date"]  # Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯
        for col_d in drop_columns:
            if col_d in df.columns:
                df.drop(columns=[col_d], inplace=True, errors="ignore")

        # Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
        if self.need_2_remove_highly_correlated_features:
            df = self.preprocessor.remove_highly_correlated_features(
                df,
                threshold=self.correlation_threshold,
                class_column=self.label_column
            )

        # Ø§ÛŒÙ…Ù¾ÛŒÙˆØª
        df_imputed = pd.DataFrame(self.preprocessor.imputer.fit_transform(df), columns=df.columns)

        # ØªÙÚ©ÛŒÚ© X,y
        X = df_imputed.drop(columns=[self.label_column])
        y = df_imputed[self.label_column]

        # ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´/Ø¢Ø²Ù…ÙˆÙ†
        x_train, x_test, y_train, y_test = train_test_split(
            X,
            y,
            test_size=self.test_size,
            random_state=self.random_state
        )

        # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ
        x_train_selected = self.preprocessor.select_features(x_train, y_train)
        x_test_selected = x_test[x_train_selected.columns]

        # Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ SMOTE
        if self.do_balance:
            logging.info("ğŸ”µ Ø§Ø¹Ù…Ø§Ù„ SMOTE Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ù„Ø§Ù†Ø³ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§")
            x_train_bal, y_train_bal = SMOTE(random_state=self.random_state).fit_resample(x_train_selected, y_train)
        else:
            logging.info("ğŸ”µ Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SMOTE")
            x_train_bal, y_train_bal = x_train_selected, y_train

        # Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ
        self.x_train = x_train_bal
        self.y_train = y_train_bal
        self.x_test = x_test_selected
        self.y_test = y_test
        self.original_df = df.copy()

        logging.info("âœ… [Step1] Ù…Ø±Ø­Ù„Ù‡ Ø§ÙˆÙ„ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
        return (self.x_train, self.y_train, self.x_test, self.y_test, self.original_df)


###########################################
# Ú¯Ø§Ù… Ø³ÙˆÙ…: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø²ÛŒØ§Ù† (Cost Computation)
###########################################
class ParsianCostMatrix:
    """
    Ø¯Ø± Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù† Ù†Ù‚Ø¯ÛŒ (Ù…Ø«Ù„Ø§Ù‹ approval_amount, interest_amount)
    Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

    ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… dataframe ØªØ³Øª (x_test) Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ… Ú©Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¯Ø± Ø¢Ù† ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.
    Ù…Ø«Ù„Ø§Ù‹ approval_amount, interest_amount.

    Ø³Ù¾Ø³ Ú†Ù‡Ø§Ø± Ù†ÙˆØ¹ Ø²ÛŒØ§Ù† Ø§ØµÙ„ÛŒ Ø±Ø§ ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:
      Î»_PP, Î»_NN (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 0)
      Î»_PN (Ø²ÛŒØ§Ù† Ù¾Ø°ÛŒØ±Ø´ Ø§Ø´ØªØ¨Ø§Ù‡)
      Î»_NP (Ø²ÛŒØ§Ù† Ø±Ø¯ Ø§Ø´ØªØ¨Ø§Ù‡)

    Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù†ÛŒØ§Ø²Ø´ Ø§ÛŒÙ† ÙØ±Ù…ÙˆÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ú©Ù†Ø¯.
    """

    def __init__(self, df_test: pd.DataFrame, approval_col="approval_amount", interest_col="interest_amount"):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - df_test: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†ØŒ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ù„Ø§Ø²Ù…
          - approval_col: Ù†Ø§Ù… Ø³ØªÙˆÙ†ÛŒ Ú©Ù‡ Ø§ØµÙ„ ÙˆØ§Ù… Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯ (approval_amount)
          - interest_col: Ù†Ø§Ù… Ø³ØªÙˆÙ†ÛŒ Ú©Ù‡ Ø³ÙˆØ¯ Ø¨Ø§Ù„Ù‚ÙˆÙ‡ ÛŒØ§ Ù…Ø¨Ù„Øº Ø¨Ù‡Ø±Ù‡ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ (interest_amount)
        """
        self.df_test = df_test.reset_index(drop=True)  # Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø±ÛŒØ³Øª Ø´ÙˆØ¯
        self.approval_col = approval_col
        self.interest_col = interest_col

        # Ø¯Ø± Ø§ÛŒÙ† Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙ…ÛŒÙ… Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
        # Ù…Ø«Ø§Ù„: cost_matrix[i] = {
        #    "PP": val, "PN": val, "BP": val, "BN": val, "NP": val, "NN": val
        # }
        self.cost_matrix = []

    def compute_costs(self):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²ÛŒØ§Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯ Ø¯Ø± df_test.
        Ø¯Ø± Ø§ÛŒÙ† Ù…Ø«Ø§Ù„ØŒ ÙØ±Ù…ÙˆÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø¯ÛŒÙ† ØµÙˆØ±Øª ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:
          Î»_PP = 0
          Î»_NN = 0
          Î»_PN = interest_amount
          Î»_NP = approval_amount + interest_amount
          (Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Î»_BP Ùˆ Î»_BN Ù‡Ù… Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒÙ…)
        """
        if self.approval_col not in self.df_test.columns or self.interest_col not in self.df_test.columns:
            raise ValueError("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²ÛŒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")

        for i in range(len(self.df_test)):
            principal = float(self.df_test.loc[i, self.approval_col] or 0.0)
            interest = float(self.df_test.loc[i, self.interest_col] or 0.0)

            cost_pp = 0.0
            cost_nn = 0.0
            cost_pn = interest  # Ù¾Ø°ÛŒØ±Ø´ Ø§Ø´ØªØ¨Ø§Ù‡ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ú©Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹ ØºÛŒØ±Ù†Ú©ÙˆÙ„ Ø§Ø³Øª
            cost_np = principal + interest  # Ø±Ø¯ Ø§Ø´ØªØ¨Ø§Ù‡ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ú©Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù†Ú©ÙˆÙ„ Ø§Ø³Øª

            # Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ… Ù…Ø±Ø²ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒÙ…:
            # cost_bp = ...
            # cost_bn = ...

            self.cost_matrix.append({
                "PP": cost_pp,
                "NN": cost_nn,
                "PN": cost_pn,
                "NP": cost_np
                # "BP": cost_bp,
                # "BN": cost_bn
            })

    def get_cost_for_sample(self, index: int):
        """
        Ú¯Ø±ÙØªÙ† Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø±Ú©ÙˆØ±Ø¯ iØ§Ù….
        Ø®Ø±ÙˆØ¬ÛŒ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ PP, PN, NP, NN (Ùˆ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ BP, BN)
        """
        return self.cost_matrix[index]

    def get_all_costs(self):
        """ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ Ú©Ù„ cost_matrix Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§. """
        return self.cost_matrix


###########################################
# ØªØ³Øª Ú©Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§ÛŒÙ† ÙØ§ÛŒÙ„)
###########################################
if __name__ == "__main__":
    os.environ["LOKY_MAX_CPU_COUNT"] = "8"

    logging.basicConfig(level=logging.INFO)

    # Ø³Ø§Ø®Øª Ø¢Ø¨Ø¬Ú©Øª Ù…Ø®Ø²Ù† Ø¯Ø§Ø¯Ù‡ (LoanRepository)
    repo = LoanRepository()

    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ (ParsianPreprocessingManager)
    prep_manager = ParsianPreprocessingManager(
        repository=repo,
        limit_records=5000,
        label_column="status",
        imputation_strategy="mean",
        need_2_remove_highly_correlated_features=False,
        correlation_threshold=0.9,
        do_balance=True,
        test_size=0.2,
        random_state=42
    )

    x_train, y_train, x_test, y_test, original_df = prep_manager.step1_process_data()
    if x_train is None:
        logging.error("Ú¯Ø§Ù… Ø§ÙˆÙ„ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
        exit(1)

    # 2) Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø§Ù… Ø¯ÙˆÙ…: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„
    default_model = ParsianDefaultProbabilityModel(
        model_type="lightgbm",
        n_estimators=100,
        learning_rate=0.05,
        random_state=42
    )
    default_model.fit_model(x_train, y_train)
    probabilities_test = default_model.predict_default_probability(x_test)

    logging.info(f"Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ† 5 Ù†Ù…ÙˆÙ†Ù‡: {probabilities_test[:5]}")
    logging.info("Ú¯Ø§Ù… Ø¯ÙˆÙ… (Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    # 3) Ú¯Ø§Ù… Ø³ÙˆÙ…: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø²ÛŒØ§Ù†
    # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… x_test Ø¯Ø§Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ approval_amount Ùˆ interest_amount Ø§Ø³Øª.
    cost_calc = ParsianCostMatrix(df_test=x_test, approval_col="approval_amount", interest_col="interest_amount")
    cost_calc.compute_costs()
    all_costs = cost_calc.get_all_costs()

    logging.info(f"Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² cost_matrix[0]: {all_costs[0]}")
    logging.info("Ú¯Ø§Ù… Ø³ÙˆÙ… (Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø²ÛŒØ§Ù†) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
