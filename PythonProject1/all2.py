import logging
import os
from datetime import datetime

import numpy as np
import pandas as pd
from colorlog import ColoredFormatter
from numpy.f2py.cfuncs import needs
# ------------------------------------------------------------
# Ø¨Ø®Ø´ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ SQLAlchemy Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ ØªØ¹Ø±ÛŒÙ Ø§Ù†ØªÛŒØªÛŒ
# ------------------------------------------------------------
from sqlalchemy import create_engine, Column, Integer, BigInteger, String, Date, DateTime, Numeric, Float
from sqlalchemy.orm import declarative_base, sessionmaker

Base = declarative_base()
protected_columns = ['approval_amount', 'interest_amount']

formatter = ColoredFormatter(
    "%(log_color)s%(asctime)s - %(levelname)s - %(message)s",
    datefmt=None,
    reset=True,
    log_colors={
        'DEBUG': 'cyan',
        'INFO': 'white',
        'WARNING': 'yellow',
        'ERROR': 'red',
        'CRITICAL': 'bold_red',
    }
)

handler = logging.StreamHandler()
handler.setFormatter(formatter)

logger = logging.getLogger()
logger.addHandler(handler)
logger.setLevel(logging.INFO)


class ParsianLoan(Base):
    __tablename__ = "parsian_loan"

    # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ù…Ø·Ø§Ø¨Ù‚ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ parsian_loan
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    insert_sysdate = Column(DateTime, nullable=False, default=datetime.utcnow)
    branch_code = Column(Integer, nullable=False)
    branchname = Column(String(100), nullable=True)
    client_id = Column(Integer, nullable=True)
    loan_file_numberr = Column(BigInteger, nullable=True)
    sit_flag = Column(String(1), nullable=True)
    interest_rate = Column(Numeric(19, 2), nullable=True)
    total_repayment_up_to_now = Column(Numeric(28, 8), nullable=True)
    commission_amount_remain = Column(Numeric(28, 8), nullable=True)
    charge = Column(Numeric(28, 8), nullable=True)
    discount = Column(Numeric(28, 8), nullable=True)
    advance_pay_to_total_cash = Column(Numeric(28, 8), nullable=True)
    advance_pay_to_remain_non_cash = Column(Numeric(28, 8), nullable=True)
    is_installment = Column(String(1), nullable=True)
    interest_sum = Column(Numeric(28, 8), nullable=True)
    installment_number_remain = Column(Integer, nullable=True)
    receivable_installment_number = Column(Integer, nullable=True)
    first_passed = Column(Date, nullable=True)
    total_payment_up_to_now = Column(Numeric(28, 8), nullable=True)
    finalized_loan_amount = Column(Numeric(28, 8), nullable=True)
    penalty = Column(Numeric(28, 8), nullable=True)
    first_payment_date_in_du = Column(Date, nullable=True)
    principal_sum = Column(Numeric(28, 8), nullable=True)
    advance_pay = Column(Numeric(28, 8), nullable=True)
    sit_duration = Column(Integer, nullable=True)
    sit_duration_day = Column(Integer, nullable=True)
    sit_distribute_phases = Column(Integer, nullable=True)
    sit_fast_receive_percent = Column(Float, nullable=True)
    frequency = Column(Integer, nullable=True)
    customer_obligation_amount = Column(Numeric(28, 8), nullable=True)
    customer_share_cash_amount = Column(Numeric(28, 8), nullable=True)
    customer_share_non_cash_amount = Column(Numeric(28, 8), nullable=True)
    bank_share_cash_amount = Column(Numeric(28, 8), nullable=True)
    bank_share_non_cash_amount = Column(Numeric(28, 8), nullable=True)
    first_over_due = Column(Date, nullable=True)
    loan_duration_day = Column(Integer, nullable=True)
    loan_file_number = Column(BigInteger, nullable=True)
    create_date = Column(Date, nullable=True)
    long_title = Column(String(255), nullable=True)
    status = Column(String(255), nullable=True)
    contract = Column(String(255), nullable=True)
    approval_amount = Column(Numeric(28, 8), nullable=True)
    title = Column(String(255), nullable=True)
    inc_commission_amount = Column(Numeric(28, 8), nullable=True)
    interest_amount = Column(Numeric(28, 8), nullable=True)
    obligation_penalty = Column(Numeric(28, 8), nullable=True)
    passed_date = Column(Date, nullable=True)
    penalty_interest = Column(Numeric(28, 8), nullable=True)
    to_due_date = Column(Numeric(28, 8), nullable=True)
    to_end_of_month = Column(Numeric(28, 8), nullable=True)
    due_date = Column(Date, nullable=True)

    def __repr__(self):
        return f"<ParsianLoan(id={self.id}, branch_code={self.branch_code}, client_id={self.client_id})>"


class LoanRepository:
    """
    Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ parsian_loan Ø¨Ø§ SQLAlchemy.
    """

    def __init__(self):
        # ÙØ±Ø¶ Ú©Ù†ÛŒØ¯ Connection String Ø±Ø§ Ø¯Ø± Ù…ØªØºÛŒØ±Ù…Ø­ÛŒØ·ÛŒ DB_CONNECTION_STRING Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒÙ….
        self.db_conn_str = os.getenv("DB_CONNECTION_STRING", "mysql+pymysql://root:pass@localhost:3306/ln")
        self.engine = create_engine(self.db_conn_str)
        SessionLocal = sessionmaker(bind=self.engine)
        self.session = SessionLocal()

    def fetch_loans(self, limit=10000):
        """
        ÙˆØ§Ú©Ø´ÛŒ Ø­Ø¯Ø§Ú©Ø«Ø± `limit` Ø±Ú©ÙˆØ±Ø¯ Ø§Ø² Ø¬Ø¯ÙˆÙ„ parsian_loan.
        Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ ÛŒÚ© DataFrame Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
        """
        loans = self.session.query(ParsianLoan).limit(limit).all()
        if not loans:
            logging.warning("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return pd.DataFrame()

        columns = [c.name for c in ParsianLoan.__table__.columns]
        data = {}
        for col in columns:
            data[col] = [getattr(loan, col) for loan in loans]
        df = pd.DataFrame(data)
        logging.info(f"âœ… {len(df)} Ø±Ú©ÙˆØ±Ø¯ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ (parsian_loan).")
        return df


###########################################
# Ú¯Ø§Ù… Ø¯ÙˆÙ…: Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ (Default Probability)
###########################################
from lightgbm import LGBMClassifier

class ParsianDefaultProbabilityModel:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú¯Ø§Ù… Ø¯ÙˆÙ… Ø¯Ø± pseudocodeorg:
    - Ø¢Ù…ÙˆØ²Ø´ ÛŒÚ© Ù…Ø¯Ù„ (Ù…Ø«Ù„Ø§Ù‹ LightGBM) Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
    - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†
    """

    def __init__(
        self,
        model_type="lightgbm",
        n_estimators=100,
        learning_rate=0.05,
        random_state=42,
        **kwargs
    ):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - model_type: Ù†ÙˆØ¹ Ù…Ø¯Ù„ (lightgbm, xgboost ÛŒØ§ Ù‡Ø± Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ)
          - n_estimators, learning_rate: Ù‡Ø§ÛŒÙ¾Ø±Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
          - random_state: Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ØªÙˆÙ„ÛŒØ¯ Ù¾Ø°ÛŒØ±ÛŒ
          - kwargs: Ø³Ø§ÛŒØ± Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡ Ù…Ø¯Ù„
        """

        self.model_type = model_type
        self.n_estimators = n_estimators
        self.learning_rate = learning_rate
        self.random_state = random_state
        self.model = None
        self.default_probabilities_ = None  # Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ test

        self.kwargs = kwargs

    def fit_model(self, x_train, y_train):
        """
        Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ:
        Ø¯Ø± Ø§ÛŒÙ† Ù…Ø«Ø§Ù„ØŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ LightGBM Ø§Ø³Øª.
        """
        if self.model_type.lower() == "lightgbm":
            logging.info("ğŸ”µ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LightGBM...")
            self.model = LGBMClassifier(
                n_estimators=self.n_estimators,
                learning_rate=self.learning_rate,
                random_state=self.random_state,
                **self.kwargs
            )
        else:
            raise ValueError("ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ù…Ø¯Ù„ lightgbm Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„).")

        self.model.fit(x_train, y_train)
        logging.info("âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

    def predict_default_probability(self, x_test):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª.
        Ø®Ø±ÙˆØ¬ÛŒ: ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ NumPy Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø­ØªÙ…Ø§Ù„ (Ø¨ÛŒÙ† Û° Ùˆ Û±)
        """
        if not self.model:
            raise ValueError("Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø¯Ù„ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯ (fit_model).")

        logging.info("ğŸ”µ Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†...")
        probs = self.model.predict_proba(x_test)
        # Ú†ÙˆÙ† Ø®Ø±ÙˆØ¬ÛŒ predict_proba Ø¯Ùˆ Ø³ØªÙˆÙ† [Prob_of_Class_0, Prob_of_Class_1] Ø§Ø³ØªØŒ
        # Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø³ØªÙˆÙ† Ø¯ÙˆÙ… (Ú©Ù„Ø§Ø³ Û±) Ø§Ø³Øª.
        self.default_probabilities_ = probs[:, 1]
        return self.default_probabilities_

    def get_model(self):
        """ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø´ÛŒØ¡ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡. """
        return self.model


# ------------------------------------------------------------
# Ú¯Ø§Ù… Ø§ÙˆÙ„: Preprocessing Manager Ùˆ Preprocessor
# ------------------------------------------------------------
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import RFECV
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE


class LoanPreprocessor:
    """
    Ú©Ù„Ø§Ø³ Ù…Ø³Ø¦ÙˆÙ„ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´:
    - ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨ (status) Ø¨Ù‡ Ù†Ú©ÙˆÙ„/ØºÛŒØ±Ù†Ú©ÙˆÙ„ (Û° ÛŒØ§ Û±)
    - ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ ÛŒØ§ Ø²Ù…Ø§Ù†
    - Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
    - Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ú©Ù…Ú© LGBM + RFECV
    - Ø§ÛŒÙ…Ù¾ÛŒÙˆØª Ø¯Ø§Ø¯Ù‡ (SimpleImputer)
    """

    def __init__(self, imputation_strategy="mean"):
        self.imputer = SimpleImputer(strategy=imputation_strategy)

    def convert_labels(self, df, label_column="status"):
        logging.info(f"[LoanPreprocessor] ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨: {label_column}")
        if label_column not in df.columns:
            raise ValueError(f"Ø³ØªÙˆÙ† {label_column} Ø¯Ø± Ø¯Ø§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

        # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± {"Ù…Ø´ÙƒÙˆÙƒ Ø§Ù„ÙˆØµÙˆÙ„", "Ù…Ø¹ÙˆÙ‚", "Ø³Ø±Ø±Ø³ÙŠØ¯ Ú¯Ø°Ø´ØªÙ‡"} => 1
        default_statuses = {"Ù…Ø´ÙƒÙˆÙƒ Ø§Ù„ÙˆØµÙˆÙ„", "Ù…Ø¹ÙˆÙ‚", "Ø³Ø±Ø±Ø³ÙŠØ¯ Ú¯Ø°Ø´ØªÙ‡"}
        df[label_column] = df[label_column].apply(lambda x: 1 if x in default_statuses else 0)
        return df

    def convert_dataframe_columns(self, df):
        """
        ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ timestamp Ùˆ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ object Ø¨Ù‡ numeric.
        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² LabelEncoder Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        """
        for col in df.columns:
            if np.issubdtype(df[col].dtype, np.datetime64):
                df[col] = pd.to_datetime(df[col]).apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan)
            elif df[col].dtype == 'object':
                try:
                    df[col] = pd.to_numeric(df[col])
                except Exception:
                    le = LabelEncoder()
                    df[col] = le.fit_transform(df[col].astype(str))
        return df

    def remove_highly_correlated_features(self, data, threshold=0.9, class_column=None):
        new_data = data.copy()
        numeric_cols = new_data.select_dtypes(include=[np.number]).columns.tolist()
        if class_column and class_column in numeric_cols:
            numeric_cols.remove(class_column)

        protected_columns = ["approval_amount", "interest_amount"]  # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù†Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯
        numeric_cols = [c for c in numeric_cols if c not in protected_columns]

        corr_matrix = new_data[numeric_cols].corr()
        attributes_to_remove = set()
        for i in range(len(numeric_cols) - 1):
            for j in range(i + 1, len(numeric_cols)):
                col_i = numeric_cols[i]
                col_j = numeric_cols[j]
                corr_value = corr_matrix.loc[col_i, col_j]
                if abs(corr_value) > threshold:
                    logging.info(f"Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§: {col_i} - {col_j} => {corr_value:.2f}, Ø­Ø°Ù {col_j}")
                    attributes_to_remove.add(col_j)

        for col_r in attributes_to_remove:
            if col_r in new_data.columns:
                new_data.drop(columns=[col_r], inplace=True)

        return new_data

    def select_features(self, X, y):
        lgbm_estimator = LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42, verbose=-1)
        rfecv = RFECV(estimator=lgbm_estimator, step=1, cv=5, scoring='accuracy', n_jobs=-1, verbose=0)
        rfecv.fit(X, y)
        selected_features = list(X.columns[rfecv.support_])
        for col in protected_columns:
            if col in X.columns and col not in selected_features:
                selected_features.append(col)
        not_selected_features = [col for col in X.columns if col not in selected_features]
        logging.info("ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡: " + ", ".join(selected_features))
        logging.info("ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡: " + ", ".join(not_selected_features))
        return X.loc[:, selected_features]


class ParsianPreprocessingManager:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ Ú¯Ø§Ù… Ø§ÙˆÙ„ (Preprocessing) Ø§Ø² pseudocodeorg.
    """

    def __init__(
            self,
            repository,
            limit_records=10000,
            label_column="status",
            imputation_strategy="mean",
            need_2_remove_highly_correlated_features=False,
            correlation_threshold=0.9,
            do_balance=True,
            test_size=0.2,
            random_state=42
    ):
        self.repository = repository
        self.limit_records = limit_records
        self.label_column = label_column
        self.imputation_strategy = imputation_strategy
        self.correlation_threshold = correlation_threshold
        self.need_2_remove_highly_correlated_features = need_2_remove_highly_correlated_features
        self.do_balance = do_balance
        self.test_size = test_size
        self.random_state = random_state

        self.x_train = None
        self.y_train = None
        self.x_test = None
        self.y_test = None
        self.original_df = None
        self.preprocessor = None

    def step1_process_data(self):
        """
        1) ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² parsian_loan
        2) ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨ Ù†Ú©ÙˆÙ„ => 0/1
        3) ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ† => Ø¹Ø¯Ø¯ÛŒ
        4) Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
        5) Ø§ÛŒÙ…Ù¾ÛŒÙˆØª
        6) ØªÙÚ©ÛŒÚ© X,y
        7) train_test_split
        8) Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ
        9) Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ SMOTE (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)

        Ø®Ø±ÙˆØ¬ÛŒ: (x_train, y_train, x_test, y_test, original_df)
        """
        logging.info("ğŸ”µ [Step1] Ø´Ø±ÙˆØ¹ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Preprocessing).")

        df = self.repository.fetch_loans(limit=self.limit_records)
        if df.empty:
            logging.error("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª.")
            return None, None, None, None, None
        logging.info(f"ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ø¯Ø±ÛŒØ§ÙØªÛŒ: {len(df)}")

        self.preprocessor = LoanPreprocessor(imputation_strategy=self.imputation_strategy)

        # Ø¨Ø±Ú†Ø³Ø¨ Ù†Ú©ÙˆÙ„
        df = self.preprocessor.convert_labels(df, label_column=self.label_column)

        # ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ†
        df = self.preprocessor.convert_dataframe_columns(df)

        # Ù…Ø«Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø¨Ø±Ø®ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        drop_columns = ["create_date"]  # Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯
        for col_d in drop_columns:
            if col_d in df.columns:
                df.drop(columns=[col_d], inplace=True, errors="ignore")

        # Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
        if self.need_2_remove_highly_correlated_features:
            df = self.preprocessor.remove_highly_correlated_features(
                df,
                threshold=self.correlation_threshold,
                class_column=self.label_column
            )

        # Ø§ÛŒÙ…Ù¾ÛŒÙˆØª
        df_imputed = pd.DataFrame(self.preprocessor.imputer.fit_transform(df), columns=df.columns)

        # ØªÙÚ©ÛŒÚ© X,y
        X = df_imputed.drop(columns=[self.label_column])
        y = df_imputed[self.label_column]

        # ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´/Ø¢Ø²Ù…ÙˆÙ†
        x_train, x_test, y_train, y_test = train_test_split(
            X,
            y,
            test_size=self.test_size,
            random_state=self.random_state
        )

        # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ
        x_train_selected = self.preprocessor.select_features(x_train, y_train)
        x_test_selected = x_test[x_train_selected.columns]

        # Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ SMOTE
        if self.do_balance:
            logging.info("ğŸ”µ Ø§Ø¹Ù…Ø§Ù„ SMOTE Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ù„Ø§Ù†Ø³ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§")
            x_train_bal, y_train_bal = SMOTE(random_state=self.random_state).fit_resample(x_train_selected, y_train)
        else:
            logging.info("ğŸ”µ Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SMOTE")
            x_train_bal, y_train_bal = x_train_selected, y_train

        # Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ
        self.x_train = x_train_bal
        self.y_train = y_train_bal
        self.x_test = x_test_selected
        self.y_test = y_test
        self.original_df = df.copy()

        logging.info("âœ… [Step1] Ù…Ø±Ø­Ù„Ù‡ Ø§ÙˆÙ„ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
        return (self.x_train, self.y_train, self.x_test, self.y_test, self.original_df)


###########################################
# ØªØ³Øª Ú©Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§ÛŒÙ† ÙØ§ÛŒÙ„)
###########################################
if __name__ == "__main__":
    os.environ["LOKY_MAX_CPU_COUNT"] = "8"

    logging.basicConfig(level=logging.INFO)

    # Ø³Ø§Ø®Øª Ø¢Ø¨Ø¬Ú©Øª Ù…Ø®Ø²Ù† Ø¯Ø§Ø¯Ù‡ (LoanRepository)
    repo = LoanRepository()

    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ (ParsianPreprocessingManager)
    prep_manager = ParsianPreprocessingManager(
        repository=repo,
        limit_records=5000,
        label_column="status",
        imputation_strategy="mean",
        need_2_remove_highly_correlated_features=False,
        correlation_threshold=0.9,
        do_balance=True,
        test_size=0.2,
        random_state=42
    )

    x_train, y_train, x_test, y_test, original_df = prep_manager.step1_process_data()
    if x_train is None:
        logging.error("Ú¯Ø§Ù… Ø§ÙˆÙ„ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
        exit(1)

    # 2) Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø§Ù… Ø¯ÙˆÙ…: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„
    default_model = ParsianDefaultProbabilityModel(
        model_type="lightgbm",
        n_estimators=100,
        learning_rate=0.05,
        random_state=42
    )
    default_model.fit_model(x_train, y_train)
    probabilities_test = default_model.predict_default_probability(x_test)

    logging.info(f"Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ† 5 Ù†Ù…ÙˆÙ†Ù‡: {probabilities_test[:5]}")
    logging.info("Ú¯Ø§Ù… Ø¯ÙˆÙ… (Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

