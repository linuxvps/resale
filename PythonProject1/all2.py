import logging
import os
from datetime import datetime

import pandas as pd
from colorlog import ColoredFormatter
# ------------------------------------------------------------
# Ø¨Ø®Ø´ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ SQLAlchemy Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ ØªØ¹Ø±ÛŒÙ Ø§Ù†ØªÛŒØªÛŒ
# ------------------------------------------------------------
from sqlalchemy import create_engine, Column, Integer, BigInteger, String, Date, DateTime, Numeric, Float
from sqlalchemy.orm import declarative_base, sessionmaker

Base = declarative_base()
protected_columns = ['approval_amount', 'interest_amount']

formatter = ColoredFormatter("%(log_color)s%(asctime)s - %(levelname)s - %(message)s", datefmt=None, reset=True,
    log_colors={'DEBUG': 'cyan', 'INFO': 'white', 'WARNING': 'yellow', 'ERROR': 'red', 'CRITICAL': 'bold_red', })

handler = logging.StreamHandler()
handler.setFormatter(formatter)

logger = logging.getLogger()
logger.addHandler(handler)
logger.setLevel(logging.INFO)

pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.float_format', lambda x: '%.2f' % x)

###########################################
# Ù¾Ù„Ø§Øª
###########################################
import matplotlib.pyplot as plt
import numpy as np
from typing import Tuple


class Plot:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨ØµØ±ÛŒâ€ŒØ³Ø§Ø²ÛŒ ØªÙˆØ²ÛŒØ¹ Ø§Ø­ØªÙ…Ø§Ù„â€ŒÙ‡Ø§.
    """

    def __init__(self) -> None:
        pass

    def visualize_distribution(self, probabilities: np.ndarray, bins: int = 20,
                               figsize: Tuple[int, int] = (10, 6)) -> None:
        """
        Ù†Ù…ÙˆØ¯Ø§Ø± Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… ØªÙˆØ²ÛŒØ¹ Ø§Ø­ØªÙ…Ø§Ù„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¢Ø±Ø§ÛŒÙ‡ ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø³Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        Ø¨Ø§ Ø§ÙØ²ÙˆØ¯Ù† Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø§Ù†Ù†Ø¯ Ø®Ø· Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†ØŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ù…Ø­ÙˆØ± Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª grid.

        :param probabilities: Ø¢Ø±Ø§ÛŒÙ‡ numpy Ø´Ø§Ù…Ù„ Ø§Ø­ØªÙ…Ø§Ù„â€ŒÙ‡Ø§.
        :param bins: ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù… (Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 20).
        :param figsize: Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø´Ú©Ù„ Ù†Ù…ÙˆØ¯Ø§Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶ (10, 6)).
        """
        plt.figure(figsize=figsize)

        # Ø±Ø³Ù… Ù‡ÛŒØ³ØªÙˆÚ¯Ø±Ø§Ù…
        n, bins, patches = plt.hist(probabilities, bins=bins, edgecolor='black',
                                    alpha=0.7, color='skyblue')

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø®Ø· Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†
        mean_val = np.mean(probabilities)
        plt.axvline(mean_val, color='red', linestyle='dashed', linewidth=2,
                    label=f'Mean = {mean_val:.2f}')

        # Ø§ÙØ²ÙˆØ¯Ù† Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±
        plt.title("Distribution of Default Probabilities", fontsize=16)
        plt.xlabel("Probability", fontsize=14)
        plt.ylabel("Frequency", fontsize=14)
        plt.xticks(fontsize=12)
        plt.yticks(fontsize=12)
        plt.grid(True, linestyle='--', alpha=0.6)
        plt.legend(fontsize=12)
        plt.tight_layout()
        plt.show()


class ParsianLoan(Base):
    __tablename__ = "parsian_loan"

    # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ù…Ø·Ø§Ø¨Ù‚ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ parsian_loan
    id = Column(BigInteger, primary_key=True, autoincrement=True)
    insert_sysdate = Column(DateTime, nullable=False, default=datetime.utcnow)
    branch_code = Column(Integer, nullable=False)
    branchname = Column(String(100), nullable=True)
    client_id = Column(Integer, nullable=True)
    loan_file_numberr = Column(BigInteger, nullable=True)
    sit_flag = Column(String(1), nullable=True)
    interest_rate = Column(Numeric(19, 2), nullable=True)
    total_repayment_up_to_now = Column(Numeric(28, 8), nullable=True)
    commission_amount_remain = Column(Numeric(28, 8), nullable=True)
    charge = Column(Numeric(28, 8), nullable=True)
    discount = Column(Numeric(28, 8), nullable=True)
    advance_pay_to_total_cash = Column(Numeric(28, 8), nullable=True)
    advance_pay_to_remain_non_cash = Column(Numeric(28, 8), nullable=True)
    is_installment = Column(String(1), nullable=True)
    interest_sum = Column(Numeric(28, 8), nullable=True)
    installment_number_remain = Column(Integer, nullable=True)
    receivable_installment_number = Column(Integer, nullable=True)
    first_passed = Column(Date, nullable=True)
    total_payment_up_to_now = Column(Numeric(28, 8), nullable=True)
    finalized_loan_amount = Column(Numeric(28, 8), nullable=True)
    penalty = Column(Numeric(28, 8), nullable=True)
    first_payment_date_in_du = Column(Date, nullable=True)
    principal_sum = Column(Numeric(28, 8), nullable=True)
    advance_pay = Column(Numeric(28, 8), nullable=True)
    sit_duration = Column(Integer, nullable=True)
    sit_duration_day = Column(Integer, nullable=True)
    sit_distribute_phases = Column(Integer, nullable=True)
    sit_fast_receive_percent = Column(Float, nullable=True)
    frequency = Column(Integer, nullable=True)
    customer_obligation_amount = Column(Numeric(28, 8), nullable=True)
    customer_share_cash_amount = Column(Numeric(28, 8), nullable=True)
    customer_share_non_cash_amount = Column(Numeric(28, 8), nullable=True)
    bank_share_cash_amount = Column(Numeric(28, 8), nullable=True)
    bank_share_non_cash_amount = Column(Numeric(28, 8), nullable=True)
    first_over_due = Column(Date, nullable=True)
    loan_duration_day = Column(Integer, nullable=True)
    loan_file_number = Column(BigInteger, nullable=True)
    create_date = Column(Date, nullable=True)
    long_title = Column(String(255), nullable=True)
    status = Column(String(255), nullable=True)
    contract = Column(String(255), nullable=True)
    approval_amount = Column(Numeric(28, 8), nullable=True)
    title = Column(String(255), nullable=True)
    inc_commission_amount = Column(Numeric(28, 8), nullable=True)
    interest_amount = Column(Numeric(28, 8), nullable=True)
    obligation_penalty = Column(Numeric(28, 8), nullable=True)
    passed_date = Column(Date, nullable=True)
    penalty_interest = Column(Numeric(28, 8), nullable=True)
    to_due_date = Column(Numeric(28, 8), nullable=True)
    to_end_of_month = Column(Numeric(28, 8), nullable=True)
    due_date = Column(Date, nullable=True)

    def __repr__(self):
        return f"<ParsianLoan(id={self.id}, branch_code={self.branch_code}, client_id={self.client_id})>"


class LoanRepository:
    """
    Ø±ÛŒÙ¾Ø§Ø²ÛŒØªÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ parsian_loan Ø¨Ø§ SQLAlchemy.
    """

    def __init__(self):
        # ÙØ±Ø¶ Ú©Ù†ÛŒØ¯ Connection String Ø±Ø§ Ø¯Ø± Ù…ØªØºÛŒØ±Ù…Ø­ÛŒØ·ÛŒ DB_CONNECTION_STRING Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒÙ….
        self.db_conn_str = os.getenv("DB_CONNECTION_STRING", "mysql+pymysql://root:pass@localhost:3306/ln")
        self.engine = create_engine(self.db_conn_str)
        SessionLocal = sessionmaker(bind=self.engine)
        self.session = SessionLocal()

    def fetch_loans(self, limit=10_000):
        """
        ÙˆØ§Ú©Ø´ÛŒ Ø­Ø¯Ø§Ú©Ø«Ø± `limit` Ø±Ú©ÙˆØ±Ø¯ Ø§Ø² Ø¬Ø¯ÙˆÙ„ parsian_loan.
        Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Ù‚Ø§Ù„Ø¨ ÛŒÚ© DataFrame Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
        """
        loans = self.session.query(ParsianLoan).limit(limit).all()
        if not loans:
            logging.warning("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return pd.DataFrame()

        columns = [c.name for c in ParsianLoan.__table__.columns]
        data = {}
        for col in columns:
            data[col] = [getattr(loan, col) for loan in loans]
        df = pd.DataFrame(data)
        logging.info(f"âœ… {len(df)} Ø±Ú©ÙˆØ±Ø¯ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ (parsian_loan).")
        return df


###########################################
# Ú¯Ø§Ù… Ø¯ÙˆÙ…: Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ (Default Probability)
###########################################

class ParsianDefaultProbabilityModel:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú¯Ø§Ù… Ø¯ÙˆÙ… Ø¯Ø± pseudocodeorg:
    - Ø¢Ù…ÙˆØ²Ø´ ÛŒÚ© Ù…Ø¯Ù„ (Ù…Ø«Ù„Ø§Ù‹ LightGBM) Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
    - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†
    """

    def __init__(self, model_type="lightgbm", n_estimators=100, learning_rate=0.05, random_state=42, **kwargs):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - model_type: Ù†ÙˆØ¹ Ù…Ø¯Ù„ (lightgbm, xgboost ÛŒØ§ Ù‡Ø± Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ)
          - n_estimators, learning_rate: Ù‡Ø§ÛŒÙ¾Ø±Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
          - random_state: Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ØªÙˆÙ„ÛŒØ¯ Ù¾Ø°ÛŒØ±ÛŒ
          - kwargs: Ø³Ø§ÛŒØ± Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¯Ù„Ø®ÙˆØ§Ù‡ Ù…Ø¯Ù„
        """

        self.model_type = model_type
        self.n_estimators = n_estimators
        self.learning_rate = learning_rate
        self.random_state = random_state
        self.model = None
        self.default_probabilities_ = None  # Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ test

        self.kwargs = kwargs

    def fit_model(self, x_train, y_train):
        """
        Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ:
        Ø¯Ø± Ø§ÛŒÙ† Ù…Ø«Ø§Ù„ØŒ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ LightGBM Ø§Ø³Øª.
        """
        if self.model_type.lower() == "lightgbm":
            logging.info("ğŸ”µ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ LightGBM...")
            self.model = LGBMClassifier(n_estimators=self.n_estimators, learning_rate=self.learning_rate,
                random_state=self.random_state, **self.kwargs)
        else:
            raise ValueError("ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ù…Ø¯Ù„ lightgbm Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø¨Ø±Ø§ÛŒ Ù…Ø«Ø§Ù„).")

        self.model.fit(x_train, y_train)
        logging.info("âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

    def predict_default_probability(self, x_test):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª.
        Ø®Ø±ÙˆØ¬ÛŒ: ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ NumPy Ø§Ø² Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø­ØªÙ…Ø§Ù„ (Ø¨ÛŒÙ† Û° Ùˆ Û±)
        """
        if not self.model:
            raise ValueError("Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ÛŒØ¯ Ù…Ø¯Ù„ Ø±Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ù‡ÛŒØ¯ (fit_model).")

        logging.info("ğŸ”µ Ø¯Ø± Ø­Ø§Ù„ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†...")
        probs = self.model.predict_proba(x_test)
        # Ú†ÙˆÙ† Ø®Ø±ÙˆØ¬ÛŒ predict_proba Ø¯Ùˆ Ø³ØªÙˆÙ† [Prob_of_Class_0, Prob_of_Class_1] Ø§Ø³ØªØŒ
        # Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø³ØªÙˆÙ† Ø¯ÙˆÙ… (Ú©Ù„Ø§Ø³ Û±) Ø§Ø³Øª.
        self.default_probabilities_ = probs[:, 1]
        return self.default_probabilities_

    def get_model(self):
        """ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø´ÛŒØ¡ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡. """
        return self.model


# ------------------------------------------------------------
# Ú¯Ø§Ù… Ø§ÙˆÙ„: Preprocessing Manager Ùˆ Preprocessor
# ------------------------------------------------------------
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import RFECV
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE


class LoanPreprocessor:
    """
    Ú©Ù„Ø§Ø³ Ù…Ø³Ø¦ÙˆÙ„ Ø¹Ù…Ù„ÛŒØ§Øª Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´:
    - ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨ (status) Ø¨Ù‡ Ù†Ú©ÙˆÙ„/ØºÛŒØ±Ù†Ú©ÙˆÙ„ (Û° ÛŒØ§ Û±)
    - ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ ÛŒØ§ Ø²Ù…Ø§Ù†
    - Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
    - Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ú©Ù…Ú© LGBM + RFECV
    - Ø§ÛŒÙ…Ù¾ÛŒÙˆØª Ø¯Ø§Ø¯Ù‡ (SimpleImputer)
    """

    def __init__(self, imputation_strategy="mean"):
        self.imputer = SimpleImputer(strategy=imputation_strategy)

    def convert_labels(self, df, label_column="status"):
        logging.info(f"[LoanPreprocessor] ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨: {label_column}")
        if label_column not in df.columns:
            raise ValueError(f"Ø³ØªÙˆÙ† {label_column} Ø¯Ø± Ø¯Ø§Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")

        # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± {"Ù…Ø´ÙƒÙˆÙƒ Ø§Ù„ÙˆØµÙˆÙ„", "Ù…Ø¹ÙˆÙ‚", "Ø³Ø±Ø±Ø³ÙŠØ¯ Ú¯Ø°Ø´ØªÙ‡"} => 1
        default_statuses = {"Ù…Ø´ÙƒÙˆÙƒ Ø§Ù„ÙˆØµÙˆÙ„", "Ù…Ø¹ÙˆÙ‚", "Ø³Ø±Ø±Ø³ÙŠØ¯ Ú¯Ø°Ø´ØªÙ‡"}
        df[label_column] = df[label_column].apply(lambda x: 1 if x in default_statuses else 0)
        return df

    def convert_dataframe_columns(self, df):
        """
        ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ timestamp Ùˆ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ object Ø¨Ù‡ numeric.
        Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±ØªØŒ Ø§Ø² LabelEncoder Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        """
        for col in df.columns:
            if np.issubdtype(df[col].dtype, np.datetime64):
                df[col] = pd.to_datetime(df[col]).apply(lambda x: x.timestamp() if pd.notnull(x) else np.nan)
            elif df[col].dtype == 'object':
                try:
                    df[col] = pd.to_numeric(df[col])
                except Exception:
                    le = LabelEncoder()
                    df[col] = le.fit_transform(df[col].astype(str))
        return df

    def remove_highly_correlated_features(self, data, threshold=0.9, class_column=None):
        new_data = data.copy()
        numeric_cols = new_data.select_dtypes(include=[np.number]).columns.tolist()
        if class_column and class_column in numeric_cols:
            numeric_cols.remove(class_column)

        protected_columns = ["approval_amount", "interest_amount"]  # Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù†Ø¨Ø§ÛŒØ¯ Ø­Ø°Ù Ø´ÙˆÙ†Ø¯
        numeric_cols = [c for c in numeric_cols if c not in protected_columns]

        corr_matrix = new_data[numeric_cols].corr()
        attributes_to_remove = set()
        for i in range(len(numeric_cols) - 1):
            for j in range(i + 1, len(numeric_cols)):
                col_i = numeric_cols[i]
                col_j = numeric_cols[j]
                corr_value = corr_matrix.loc[col_i, col_j]
                if abs(corr_value) > threshold:
                    logging.info(f"Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§: {col_i} - {col_j} => {corr_value:.2f}, Ø­Ø°Ù {col_j}")
                    attributes_to_remove.add(col_j)

        for col_r in attributes_to_remove:
            if col_r in new_data.columns:
                new_data.drop(columns=[col_r], inplace=True)

        return new_data

    def select_features(self, X, y):
        lgbm_estimator = LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42, verbose=-1)
        rfecv = RFECV(estimator=lgbm_estimator, step=1, cv=5, scoring='accuracy', n_jobs=-1, verbose=0)
        rfecv.fit(X, y)
        selected_features = list(X.columns[rfecv.support_])
        for col in protected_columns:
            if col in X.columns and col not in selected_features:
                selected_features.append(col)
        not_selected_features = [col for col in X.columns if col not in selected_features]
        logging.info("ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡: " + ", ".join(selected_features))
        logging.info("ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯Ù‡: " + ", ".join(not_selected_features))
        return X.loc[:, selected_features]


class ParsianPreprocessingManager:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ Ú¯Ø§Ù… Ø§ÙˆÙ„ (Preprocessing) Ø§Ø² pseudocodeorg.
    """

    def __init__(self, repository, limit_records=10000, label_column="status", imputation_strategy="mean",
            need_2_remove_highly_correlated_features=False, correlation_threshold=0.9, do_balance=True, test_size=0.2,
            random_state=42):
        self.repository = repository
        self.limit_records = limit_records
        self.label_column = label_column
        self.imputation_strategy = imputation_strategy
        self.correlation_threshold = correlation_threshold
        self.need_2_remove_highly_correlated_features = need_2_remove_highly_correlated_features
        self.do_balance = do_balance
        self.test_size = test_size
        self.random_state = random_state

        self.x_train = None
        self.y_train = None
        self.x_test = None
        self.y_test = None
        self.original_df = None
        self.preprocessor = None

    def step1_process_data(self):
        """
        1) ÙˆØ§Ú©Ø´ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² parsian_loan
        2) ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø±Ú†Ø³Ø¨ Ù†Ú©ÙˆÙ„ => 0/1
        3) ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ† => Ø¹Ø¯Ø¯ÛŒ
        4) Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
        5) Ø§ÛŒÙ…Ù¾ÛŒÙˆØª
        6) ØªÙÚ©ÛŒÚ© X,y
        7) train_test_split
        8) Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ
        9) Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ SMOTE (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)

        Ø®Ø±ÙˆØ¬ÛŒ: (x_train, y_train, x_test, y_test, original_df)
        """
        logging.info("ğŸ”µ [Step1] Ø´Ø±ÙˆØ¹ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Preprocessing).")

        df = self.repository.fetch_loans(limit=self.limit_records)
        if df.empty:
            logging.error("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª.")
            return None, None, None, None, None
        logging.info(f"ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯ Ø¯Ø±ÛŒØ§ÙØªÛŒ: {len(df)}")

        self.preprocessor = LoanPreprocessor(imputation_strategy=self.imputation_strategy)

        # Ø¨Ø±Ú†Ø³Ø¨ Ù†Ú©ÙˆÙ„
        df = self.preprocessor.convert_labels(df, label_column=self.label_column)

        # ØªØ¨Ø¯ÛŒÙ„ Ø§Ù†ÙˆØ§Ø¹ Ø³ØªÙˆÙ†
        df = self.preprocessor.convert_dataframe_columns(df)

        # Ù…Ø«Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù Ø¨Ø±Ø®ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        drop_columns = ["create_date"]  # Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù…ÛŒâ€ŒØªÙˆØ§Ù† ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯
        for col_d in drop_columns:
            if col_d in df.columns:
                df.drop(columns=[col_d], inplace=True, errors="ignore")

        # Ø­Ø°Ù ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§Ù„Ø§
        if self.need_2_remove_highly_correlated_features:
            df = self.preprocessor.remove_highly_correlated_features(df, threshold=self.correlation_threshold,
                class_column=self.label_column)

        # Ø§ÛŒÙ…Ù¾ÛŒÙˆØª
        df_imputed = pd.DataFrame(self.preprocessor.imputer.fit_transform(df), columns=df.columns)

        # ØªÙÚ©ÛŒÚ© X,y
        X = df_imputed.drop(columns=[self.label_column])
        y = df_imputed[self.label_column]

        # ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´/Ø¢Ø²Ù…ÙˆÙ†
        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size,
            random_state=self.random_state)

        # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ
        x_train_selected = self.preprocessor.select_features(x_train, y_train)
        x_test_selected = x_test[x_train_selected.columns]

        # Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ SMOTE
        if self.do_balance:
            logging.info("ğŸ”µ Ø§Ø¹Ù…Ø§Ù„ SMOTE Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ù„Ø§Ù†Ø³ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§")
            x_train_bal, y_train_bal = SMOTE(random_state=self.random_state).fit_resample(x_train_selected, y_train)
        else:
            logging.info("ğŸ”µ Ø¹Ø¯Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SMOTE")
            x_train_bal, y_train_bal = x_train_selected, y_train

        # Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ
        self.x_train = x_train_bal
        self.y_train = y_train_bal
        self.x_test = x_test_selected
        self.y_test = y_test
        self.original_df = df.copy()

        logging.info("âœ… [Step1] Ù…Ø±Ø­Ù„Ù‡ Ø§ÙˆÙ„ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
        return (self.x_train, self.y_train, self.x_test, self.y_test, self.original_df)


###########################################
# Ú¯Ø§Ù… Ø³ÙˆÙ…: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø²ÛŒØ§Ù† (Cost Computation)
###########################################
class ParsianCostMatrix:
    """
    Ø¯Ø± Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù† Ù†Ù‚Ø¯ÛŒ (Ù…Ø«Ù„Ø§Ù‹ approval_amount, interest_amount)
    Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.

    ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… dataframe ØªØ³Øª (x_test) Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ… Ú©Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¯Ø± Ø¢Ù† ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.
    Ù…Ø«Ù„Ø§Ù‹ approval_amount, interest_amount.

    Ø³Ù¾Ø³ Ú†Ù‡Ø§Ø± Ù†ÙˆØ¹ Ø²ÛŒØ§Ù† Ø§ØµÙ„ÛŒ Ø±Ø§ ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:
      Î»_PP, Î»_NN (Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 0)
      Î»_PN (Ø²ÛŒØ§Ù† Ù¾Ø°ÛŒØ±Ø´ Ø§Ø´ØªØ¨Ø§Ù‡)
      Î»_NP (Ø²ÛŒØ§Ù† Ø±Ø¯ Ø§Ø´ØªØ¨Ø§Ù‡)

    Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù†ÛŒØ§Ø²Ø´ Ø§ÛŒÙ† ÙØ±Ù…ÙˆÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ú©Ù†Ø¯.
    """

    def __init__(self, df_test: pd.DataFrame, approval_col="approval_amount", interest_col="interest_amount"):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - df_test: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ø²Ù…ÙˆÙ†ØŒ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ù„Ø§Ø²Ù…
          - approval_col: Ù†Ø§Ù… Ø³ØªÙˆÙ†ÛŒ Ú©Ù‡ Ø§ØµÙ„ ÙˆØ§Ù… Ø±Ø§ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯ (approval_amount)
          - interest_col: Ù†Ø§Ù… Ø³ØªÙˆÙ†ÛŒ Ú©Ù‡ Ø³ÙˆØ¯ Ø¨Ø§Ù„Ù‚ÙˆÙ‡ ÛŒØ§ Ù…Ø¨Ù„Øº Ø¨Ù‡Ø±Ù‡ Ø±Ø§ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ (interest_amount)
        """
        self.df_test = df_test.reset_index(drop=True)  # Ø§Ú¯Ø± Ù„Ø§Ø²Ù… Ø§Ø³Øª Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø±ÛŒØ³Øª Ø´ÙˆØ¯
        self.approval_col = approval_col
        self.interest_col = interest_col

        # Ø¯Ø± Ø§ÛŒÙ† Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙ…ÛŒÙ… Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
        # Ù…Ø«Ø§Ù„: cost_matrix[i] = {
        #    "PP": val, "PN": val, "BP": val, "BN": val, "NP": val, "NN": val
        # }
        self.cost_matrix = []

    def compute_costs(self):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²ÛŒØ§Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯ Ø¯Ø± df_test.
        Ø¯Ø± Ø§ÛŒÙ† Ù…Ø«Ø§Ù„ØŒ ÙØ±Ù…ÙˆÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø¯ÛŒÙ† ØµÙˆØ±Øª ØªØ¹Ø±ÛŒÙ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…:
          Î»_PP = 0
          Î»_NN = 0
          Î»_PN = interest_amount
          Î»_NP = approval_amount + interest_amount
          (Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Î»_BP Ùˆ Î»_BN Ù‡Ù… Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒÙ…)
        """
        if self.approval_col not in self.df_test.columns or self.interest_col not in self.df_test.columns:
            raise ValueError("Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø²ÛŒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")

        for i in range(len(self.df_test)):
            principal = float(self.df_test.loc[i, self.approval_col] or 0.0)
            interest = float(self.df_test.loc[i, self.interest_col] or 0.0)

            cost_pp = 0.0
            cost_nn = 0.0
            cost_pn = interest  # Ù¾Ø°ÛŒØ±Ø´ Ø§Ø´ØªØ¨Ø§Ù‡ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ú©Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹ ØºÛŒØ±Ù†Ú©ÙˆÙ„ Ø§Ø³Øª
            cost_np = principal + interest  # Ø±Ø¯ Ø§Ø´ØªØ¨Ø§Ù‡ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ú©Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù†Ú©ÙˆÙ„ Ø§Ø³Øª

            # Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ… Ù…Ø±Ø²ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒÙ…:
            # cost_bp = ...
            # cost_bn = ...

            self.cost_matrix.append({"PP": cost_pp, "NN": cost_nn, "PN": cost_pn, "NP": cost_np# "BP": cost_bp,
                # "BN": cost_bn
            })

    def get_cost_for_sample(self, index: int):
        """
        Ú¯Ø±ÙØªÙ† Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø±Ú©ÙˆØ±Ø¯ iØ§Ù….
        Ø®Ø±ÙˆØ¬ÛŒ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ PP, PN, NP, NN (Ùˆ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ BP, BN)
        """
        return self.cost_matrix[index]

    def get_all_costs(self):
        """ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ Ú©Ù„ cost_matrix Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒâ€ŒÙ‡Ø§. """
        return self.cost_matrix


###########################################
# Ú¯Ø§Ù… Ú†Ù‡Ø§Ø±Ù…: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†Ù†Ø¯Ù‡Ø¯ÙÙ‡ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ NSGA-II (pymoo)
###########################################
import numpy as np
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.core.problem import Problem
from pymoo.optimize import minimize


class ParsianThresholdNSGA2:
    """
    ÛŒÚ© Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú¯Ø§Ù… Ú†Ù‡Ø§Ø±Ù… ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø³Ù‡â€ŒØ·Ø±ÙÙ‡ Ø¨Ù‡ ØµÙˆØ±Øª Ú†Ù†Ø¯Ù‡Ø¯ÙÙ‡:
      - Ù‡Ø¯Ù Ø§ÙˆÙ„: Ú©Ù…ÛŒÙ†Ù‡â€ŒÚ©Ø±Ø¯Ù† Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ
      - Ù‡Ø¯Ù Ø¯ÙˆÙ…: Ú©Ù…ÛŒÙ†Ù‡â€ŒÚ©Ø±Ø¯Ù† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù†Ø§Ø­ÛŒÙ‡ Ù…Ø±Ø²ÛŒ (BND)
      Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… NSGA-II Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ pymoo.

    ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§:
      - probabilities_test: Ø¢Ø±Ø§ÛŒÙ‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª
      - cost_matrix: Ø¢Ø±Ø§ÛŒÙ‡ ÛŒØ§ Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯
           Ù…Ø«Ø§Ù„: cost_matrix[i] = {"PP": cost_if_true_and_decide_positive,
                                   "PN": cost_if_false_and_decide_positive,
                                   "NP": cost_if_true_and_decide_negative,
                                   "NN": cost_if_false_and_decide_negative,
                                   ...}
      - true_labels: Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ø±Ú†Ø³Ø¨ ÙˆØ§Ù‚Ø¹ÛŒ (Û° ÛŒØ§ Û±)
      - pop_size: Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¬Ù…Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ NSGA2
      - n_gen: ØªØ¹Ø¯Ø§Ø¯ Ù†Ø³Ù„ (iteration) Ø¨Ø±Ø§ÛŒ NSGA2
    """

    def __init__(self, probabilities_test: np.ndarray, cost_matrix: list, true_labels: np.ndarray, pop_size=50,
            n_gen=100, step_bnd=False):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
         - step_bnd: Ø§Ú¯Ø± True Ø¨Ø§Ø´Ø¯ØŒ objective Ø¯ÙˆÙ… Ø±Ø§ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ BND Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
                     Ø§Ú¯Ø± False Ø¨Ø§Ø´Ø¯ØŒ Ù†Ø³Ø¨Øª Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ BND Ø¨Ù‡ Ú©Ù„ Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
                     (Ù‡Ø± Ø¯Ùˆ Ø±ÙˆÛŒÚ©Ø±Ø¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª.)
        """
        self.probabilities_test = probabilities_test  # Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„
        self.cost_matrix = cost_matrix  # Ø²ÛŒØ§Ù† Ù‡Ø± Ø±Ú©ÙˆØ±Ø¯
        self.true_labels = true_labels
        self.pop_size = pop_size
        self.n_gen = n_gen
        self.step_bnd = step_bnd

        self.best_solutions = None  # Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±ØªÙˆ Ø¨Ù‡â€ŒØ¯Ø³Øªâ€ŒØ¢Ù…Ø¯Ù‡
        self.front_costs = None  # Ù…Ù‚Ø¯Ø§Ø± Ø§Ù‡Ø¯Ø§Ù Ø¯Ø± Ù¾Ø§Ø±ØªÙˆ
        self.problem_instance = None

    def _decision_cost_for_sample(self, i, alpha, beta):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ iØ§Ù….
        Ø³Ù‡ Ø­Ø§Ù„Øª:
         - Ø§Ú¯Ø± p_i >= alpha => POS
         - Ø§Ú¯Ø± p_i <= beta => NEG
         - Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±Øª => BND (Ø§ÛŒÙ†Ø¬Ø§ Ù‡Ø²ÛŒÙ†Ù‡ Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø³ÙØ§Ø±Ø´ÛŒ Ú©Ø±Ø¯.)
        """
        p = self.probabilities_test[i]
        y_true = self.true_labels[i]  # 0 ÛŒØ§ 1
        costs = self.cost_matrix[i]

        if p >= alpha:
            # ØªØµÙ…ÛŒÙ… => Ù†Ú©ÙˆÙ„
            return costs["PP"] if y_true == 1 else costs["PN"]
        elif p <= beta:
            # ØªØµÙ…ÛŒÙ… => ØºÛŒØ±Ù†Ú©ÙˆÙ„
            return costs["NP"] if y_true == 1 else costs["NN"]
        else:
            # Ù…Ø±Ø²ÛŒ
            # Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒØ¯ Ù‡Ø²ÛŒÙ†Ù‡ Ù…Ø±Ø²ÛŒ Ø±Ø§ Ù‡Ù… Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯ØŒ Ø¨Ø§ÛŒØ¯ Ø¢Ù† Ø±Ø§ Ø¯Ø± cost_matrix[i] Ú¯Ù†Ø¬Ø§Ù†ÛŒØ¯
            # Ù…Ø«Ù„Ø§Ù‹ costs["BP"], costs["BN"] ...
            # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒ 0 Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
            return 0.0

    def _boundary_count_for_solution(self, alpha, beta):
        """
        ØªØ¹Ø¯Ø§Ø¯ (ÛŒØ§ Ù†Ø³Ø¨Øª) Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ Ù…Ø±Ø²ÛŒ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯:
         ÛŒØ¹Ù†ÛŒ sample i Ú©Ù‡ p_i âˆˆ (beta, alpha)
        """
        p = self.probabilities_test
        bnd_mask = (p > beta) & (p < alpha)
        bnd_count = np.sum(bnd_mask)
        if self.step_bnd:
            return bnd_count  # ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø²ÛŒ
        else:
            return bnd_count / len(p)  # Ù†Ø³Ø¨Øª Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø²ÛŒ Ø¨Ù‡ Ú©Ù„

    class ThresholdOptimizationProblem(Problem):
        """
        Ú©Ù„Ø§Ø³ Ù…Ø³Ø¦Ù„Ù‡ pymoo Ø¨Ø±Ø§ÛŒ NSGA-II.
        n_var=2 => (alpha, beta)
        n_obj=2 => Ù‡Ø¯Ù Ø§ÙˆÙ„: Ù‡Ø²ÛŒÙ†Ù‡ØŒ Ù‡Ø¯Ù Ø¯ÙˆÙ…: Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù†Ø§Ø­ÛŒÙ‡ Ù…Ø±Ø²ÛŒ
        n_constr=1 => alpha >= beta  => beta - alpha <= 0
        xl=[0,0], xu=[1,1] => alpha,beta âˆˆ [0,1]
        """

        def __init__(self, outer, ):
            """
            - outer: ÛŒÚ© Ø§Ø´Ø§Ø±Ù‡ Ø¨Ù‡ Ú©Ù„Ø§Ø³ Ø¨ÛŒØ±ÙˆÙ†ÛŒ ParsianThresholdNSGA2
                     ØªØ§ Ø¨ØªÙˆØ§Ù†ÛŒÙ… Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ probabilities_test Ùˆ ... Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ….
            """
            super().__init__(n_var=2, n_obj=2, n_constr=1, xl=np.array([0.0, 0.0]), xu=np.array([1.0, 1.0]),
                type_var=np.double)
            self.outer = outer  # Ø§Ø±Ø¬Ø§Ø¹ Ø¨Ù‡ Ú©Ù„Ø§Ø³ Ø¨ÛŒØ±ÙˆÙ†ÛŒ

        def _evaluate(self, X, out, *args, **kwargs):
            """
            X Ø¢Ø±Ø§ÛŒÙ‡â€ŒØ§ÛŒ Ø´Ú©Ù„ (N, 2) Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ù‡Ø± Ø³Ø·Ø±:
              X[i,0] = alpha
              X[i,1] = beta
            Ø¨Ø§ÛŒØ¯ 2 Ù‡Ø¯Ù Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÙˆØ¯: total_cost, boundary_size
            Ù‡Ù…Ú†Ù†ÛŒÙ† ÛŒÚ© Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: alpha >= beta => beta - alpha <= 0
            """
            n_solutions = X.shape[0]
            f1 = np.zeros(n_solutions)  # Ù‡Ø²ÛŒÙ†Ù‡
            f2 = np.zeros(n_solutions)  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø±Ø²ÛŒ

            for i_sol in range(n_solutions):
                alpha = X[i_sol, 0]
                beta = X[i_sol, 1]

                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ Ú©Ù„
                total_cost = 0.0
                for i_sample in range(len(self.outer.probabilities_test)):
                    c = self.outer._decision_cost_for_sample(i_sample, alpha, beta)
                    total_cost += c

                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ø±Ø²ÛŒ
                boundary_size = self.outer._boundary_count_for_solution(alpha, beta)

                f1[i_sol] = total_cost
                f2[i_sol] = boundary_size

            # Ù…Ø­Ø¯ÙˆØ¯ÛŒØª: alpha >= beta => (beta - alpha) <= 0
            g = np.zeros((n_solutions, 1))
            g[:, 0] = X[:, 1] - X[:, 0]  # beta - alpha => Ø¨Ø§ÛŒØ¯ <= 0

            out["F"] = np.column_stack([f1, f2])
            out["G"] = g

    def optimize(self):
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… NSGA-II Ø¨Ø±Ø§ÛŒ Ú©Ù…ÛŒÙ†Ù‡â€ŒÚ©Ø±Ø¯Ù† [cost, boundary_size]
        Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª alpha >= beta.
        """
        logging.info("ğŸ”µ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†Ù†Ø¯Ù‡Ø¯ÙÙ‡ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ NSGA-II...")

        # Ø³Ø§Ø®Øª Ù†Ù…ÙˆÙ†Ù‡ Ù…Ø³Ø¦Ù„Ù‡
        self.problem_instance = self.ThresholdOptimizationProblem(self)

        # Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… NSGA2
        algo = NSGA2(pop_size=self.pop_size)

        # Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
        res = minimize(self.problem_instance, algo, ("n_gen", self.n_gen), seed=42, verbose=False)

        self.front_costs = res.F  # Ù‡Ø¯Ùâ€ŒÙ‡Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±ØªÙˆ
        self.best_solutions = res.X  # Ø®ÙˆØ¯ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ (alpha,beta) Ø¯Ø± Ù¾Ø§Ø±ØªÙˆ
        logging.info("âœ… NSGA-II Ø¨Ù‡ Ø§ØªÙ…Ø§Ù… Ø±Ø³ÛŒØ¯. ØªØ¹Ø¯Ø§Ø¯ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±ØªÙˆ: {}".format(len(self.front_costs)))

    def get_pareto_front(self):
        """
        Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ (solutions, objectives) = (self.best_solutions, self.front_costs)
        Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ù‡Ø± solutions[i] = [alpha_i, beta_i]
              each objectives[i] = [cost_i, boundary_i]
        """
        return self.best_solutions, self.front_costs

    def get_final_solution(self):
        """
        Ø§Ø² Ù…ÛŒØ§Ù† Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±ØªÙˆØŒ Ø±Ø§Ù‡â€ŒØ­Ù„ Ù†Ù‡Ø§ÛŒÛŒ (Î±, Î²) Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ Ú©Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ø­ÛŒÙ‡ Ù…Ø±Ø²ÛŒ Ø±Ø§ Ø¨Ù‡ Ø­Ø¯Ø§Ù‚Ù„ Ø±Ø³Ø§Ù†Ø¯Ù‡ Ø§Ø³Øª.
        Ø®Ø±ÙˆØ¬ÛŒ: (final_solution, final_objectives)
          final_solution: Ø¢Ø±Ø§ÛŒÙ‡ [alpha, beta]
          final_objectives: Ø¢Ø±Ø§ÛŒÙ‡ [total_cost, boundary_size] Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø±Ø§Ù‡â€ŒØ­Ù„ Ù†Ù‡Ø§ÛŒÛŒ
        """
        solutions, objectives = self.get_pareto_front()
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø±Ø§Ù‡â€ŒØ­Ù„ Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± objective Ø¯ÙˆÙ… (boundary_size)
        best_index = np.argmin(objectives[:, 1])
        final_solution = solutions[best_index]
        final_objectives = objectives[best_index]
        return final_solution, final_objectives


###########################################
# Ú¯Ø§Ù… Ù¾Ù†Ø¬Ù…: ØªÙ‚Ø³ÛŒÙ… Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ POS/NEG/BND (Three-Way Decision)
###########################################

class ParsianThreeWayDecision:
    """
    Ø¯Ø± Ø§ÛŒÙ† Ú¯Ø§Ù…ØŒ Ø¨Ø§ Ø¯Ø§Ø´ØªÙ† Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù†Ú©ÙˆÙ„ p Ùˆ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ alpha Ùˆ betaØŒ
    Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡ Ø±Ø§ Ø¨Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø³Ù‡ Ø¯Ø³ØªÙ‡ POS/NEG/BND ØªØ®ØµÛŒØµ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ….

    Ø§Ú¯Ø±:
      p_i >= alpha  =>  POS
      p_i <= beta   =>  NEG
      otherwise     =>  BND
    """

    def __init__(self, probabilities_test: np.ndarray, alpha: float, beta: float):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - probabilities_test: Ø¢Ø±Ø§ÛŒÙ‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª
          - alpha, beta: Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ØªØµÙ…ÛŒÙ… Ø³Ù‡â€ŒØ·Ø±ÙÙ‡
        """
        self.probabilities_test = probabilities_test
        self.alpha = alpha
        self.beta = beta
        self.decisions = None  # Ù„ÛŒØ¨Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ù‡Ø± Ù†Ù…ÙˆÙ†Ù‡: POS=1, NEG=0, BND=-1 (Ù…Ø«Ù„Ø§Ù‹)

    def apply_three_way_decision(self):
        """
        Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ alpha Ùˆ betaØŒ Ø±ÙˆÛŒ probabilities_test Ø§Ø¬Ø±Ø§ Ú©Ø±Ø¯Ù‡
        Ùˆ Ø³Ù‡ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø±Ø§ Ø¨Ø§Ø²Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
        """
        n_samples = len(self.probabilities_test)
        decisions = np.zeros(n_samples, dtype=int)  # 0 => NEG, 1 => POS, -1 => BND

        for i in range(n_samples):
            p_i = self.probabilities_test[i]
            if p_i >= self.alpha:
                decisions[i] = 1  # POS
            elif p_i <= self.beta:
                decisions[i] = 0  # NEG
            else:
                decisions[i] = -1  # BND

        self.decisions = decisions
        return decisions

    def get_decisions(self):
        """
        Ø§Ú¯Ø± Ø§Ø² Ù‚Ø¨Ù„ apply_three_way_decision Ø±Ø§ ØµØ¯Ø§ Ø²Ø¯Ù‡ Ø¨Ø§Ø´ÛŒÙ…ØŒ
        ØªØµÙ…ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ….
        Ø®Ø±ÙˆØ¬ÛŒ ÛŒÚ© Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± {0=NEG, 1=POS, -1=BND}.
        """
        return self.decisions

    def get_decision_counts(self):
        """
        ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù‡Ø± Ø¯Ø³ØªÙ‡ (POS=1, NEG=0, BND=-1) Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
        Ø®Ø±ÙˆØ¬ÛŒ: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ù‡ Ø´Ú©Ù„ {1: ØªØ¹Ø¯Ø§Ø¯ POS, 0: ØªØ¹Ø¯Ø§Ø¯ NEG, -1: ØªØ¹Ø¯Ø§Ø¯ BND}
        """
        if self.decisions is None:
            self.apply_three_way_decision()
        unique, counts = np.unique(self.decisions, return_counts=True)
        return dict(zip(unique, counts))


###########################################
# Ú¯Ø§Ù… Ø´Ø´Ù…: ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø±ÙˆÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ BND
#          (Ù…Ø«Ù„Ø§Ù‹ Ø¨Ø§ Ø§Ø³ØªÚ©ÛŒÙ†Ú¯ ÛŒØ§ Ù…Ø¯Ù„ Ú©Ù…Ú©ÛŒ Ø¯ÛŒÚ¯Ø±)
###########################################
from sklearn.ensemble import StackingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier


class ParsianBNDResolver:
    """
    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ø±Ø§ Ú©Ù‡ Ø¯Ø± Ú¯Ø§Ù… Ù¾Ù†Ø¬Ù… Ø¯Ø± Ù†Ø§Ø­ÛŒÙ‡ BND ÙˆØ§Ù‚Ø¹ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ØŒ
    Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ùˆ Ø¨Ø§ ÛŒÚ© Ù…Ø¯Ù„ Ø§Ø¶Ø§ÙÛŒ (Ù…Ø«Ù„Ø§Ù‹ Ø§Ø³ØªÚ©ÛŒÙ†Ú¯) ØªØµÙ…ÛŒÙ… Ù‚Ø·Ø¹ÛŒ (POS ÛŒØ§ NEG) Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯.
    """

    def __init__(self, x_train_all: pd.DataFrame, y_train_all: pd.Series, model_type="stacking"):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - x_train_all, y_train_all: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø§ØµÙ„ÛŒ (ÛŒØ§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø²ÛŒ Ø®Ø§ØµØŸ)
          - model_type: Ù†ÙˆØ¹ Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒÙ… Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø²ÛŒ Ø¨Ù‡â€ŒÚ©Ø§Ø± Ø¨Ø±ÛŒÙ…
                       (Ø§ÛŒÙ†Ø¬Ø§ Ù…Ø«Ù„Ø§Ù‹ "stacking" ÛŒØ§ "bagging" ÛŒØ§ ...)
        """
        self.x_train_all = x_train_all
        self.y_train_all = y_train_all
        self.model_type = model_type
        self.classifier = None

    def fit_bnd_model(self):
        """
        Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø§Ø³ØªÚ©ÛŒÙ†Ú¯ ÛŒØ§ Ù‡Ø± Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø± Ø¨Ø± Ø±ÙˆÛŒ Ú©Ù„ Ø¯Ø§Ø¯Ù‡Ù” Ø¢Ù…ÙˆØ²Ø´.
        ØªÙˆØ¬Ù‡: Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… Ø¨Ù†Ø§ Ø¨Ù‡ Ù†ÛŒØ§Ø²ØŒ ÙÙ‚Ø· Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø´ÙˆØ§Ø± ÛŒØ§ Ø¨Ø®Ø´ÛŒ Ø§Ø² Ø¯ÛŒØªØ§Ø³Øª Ø±Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ….
        """
        if self.model_type.lower() == "stacking":
            # Ú†Ù†Ø¯ÛŒÙ† Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ + Ù…ØªØ§
            base_estimators = [("rf", RandomForestClassifier(n_estimators=50, random_state=42)),
                ("xgb", XGBClassifier(eval_metric="logloss", random_state=42))]
            meta_estimator = LogisticRegression(max_iter=1000, random_state=42)
            self.classifier = StackingClassifier(estimators=base_estimators, final_estimator=meta_estimator, cv=5,
                n_jobs=-1)
        else:
            # Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
            raise ValueError("ÙÙ‚Ø· Ù…Ø¯Ù„ 'stacking' Ù¾ÛŒØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.")

        logging.info("ğŸ”µ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ BNDResolver (Ø§Ø³ØªÚ©ÛŒÙ†Ú¯)...")
        self.classifier.fit(self.x_train_all, self.y_train_all)
        logging.info("âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ BNDResolver Ú©Ø§Ù…Ù„ Ø´Ø¯.")

    def resolve_bnd_samples(self, x_test: pd.DataFrame, decisions_final: np.ndarray):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
         - x_test: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª Ú©Ø§Ù…Ù„
         - decisions_final: Ø¨Ø±Ú†Ø³Ø¨ ØªØµÙ…ÛŒÙ… Ú¯Ø§Ù… Ù¾Ù†Ø¬Ù… (POS=1, NEG=0, BND=-1)
        Ø®Ø±ÙˆØ¬ÛŒ:
         - decisions_updated: Ø¢Ø±Ø§ÛŒÙ‡â€ŒÛŒ ØªØµÙ…ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ Ú©Ù‡ BNDÙ‡Ø§ Ø±Ø§ Ù†ÛŒØ² Ø¨Ù‡ POS ÛŒØ§ NEG ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        bnd_indices = np.where(decisions_final == -1)[0]
        logging.info(f"ğŸ”µ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ BND: {len(bnd_indices)}")

        if len(bnd_indices) == 0:
            logging.info("Ù‡ÛŒÚ† Ù†Ù…ÙˆÙ†Ù‡ Ù…Ø±Ø²ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. ØªØºÛŒÛŒØ±ÛŒ Ø§Ø¹Ù…Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            return decisions_final  # Ù‡Ù…Ø§Ù† Ù‚Ø¨Ù„ÛŒ

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ BND Ø§Ø² x_test
        x_test_bnd = x_test.iloc[bnd_indices]
        # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¯Ù„ Ø«Ø§Ù†ÙˆÛŒÙ‡
        y_pred_bnd = self.classifier.predict(x_test_bnd)

        # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ØªØµÙ…ÛŒÙ… Ù†Ù‡Ø§ÛŒÛŒ
        decisions_updated = decisions_final.copy()
        for idx, pred in zip(bnd_indices, y_pred_bnd):
            decisions_updated[idx] = pred  # pred=0 => NEG, pred=1 => POS
        return decisions_updated


###########################################
# Ú¯Ø§Ù… Ù‡ÙØªÙ…: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´ (Final Evaluation)
###########################################
import numpy as np
from sklearn.metrics import roc_auc_score


class ParsianFinalEvaluator:
    """
    Ø¯Ø± Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ØŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ ØªØµÙ…ÛŒÙ… (Ø¨Ø¹Ø¯ Ø§Ø² Ú¯Ø§Ù… Ø´Ø´Ù…) Ø±Ø§ Ø¨Ø§ Ø¨Ø±Ú†Ø³Ø¨ ÙˆØ§Ù‚Ø¹ÛŒ
    Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ùˆ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø±Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ú¯Ø²Ø§Ø±Ø´ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ….
    """

    def __init__(self, true_labels: np.ndarray, final_decisions: np.ndarray, probabilities_test: np.ndarray = None,
            cost_matrix: list = None):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
          - true_labels: Ø¢Ø±Ø§ÛŒÙ‡ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ ØªØ³Øª (Û° ÛŒØ§ Û±)
          - final_decisions: Ø¢Ø±Ø§ÛŒÙ‡ ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ (Û°=NEG, Û±=POS)
          - probabilities_test: Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒÙ… AUC ÛŒØ§ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„Ø§ØªÛŒ Ø±Ø§ Ø­Ø³Ø§Ø¨ Ú©Ù†ÛŒÙ…
          - cost_matrix: Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ… Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø±Ø§ Ù†ÛŒØ² Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…Ø§ÛŒÛŒÙ…. (Ù…Ø«Ù„Ø§Ù‹ Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø§Ù… Ø³ÙˆÙ…)
        """
        self.true_labels = true_labels
        self.final_decisions = final_decisions
        self.probabilities_test = probabilities_test
        self.cost_matrix = cost_matrix

    def evaluate_metrics(self):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù†Ø¸ÛŒØ±:
         - Balanced Accuracy
         - Precision, Recall, F1
         - AUC (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ probabilities_test)
         - Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ… (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ cost_matrix)
        Ø®Ø±ÙˆØ¬ÛŒ: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø´Ø§Ù…Ù„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        """

        if len(self.true_labels) != len(self.final_decisions):
            raise ValueError("Ø·ÙˆÙ„ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§ ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ Ù†Ø¯Ø§Ø±Ø¯.")

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ confusion matrix
        cm = confusion_matrix(self.true_labels, self.final_decisions)
        # cm Ø³Ø§Ø®ØªØ§Ø± [[TN, FP], [FN, TP]]
        TN, FP, FN, TP = cm.ravel()

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Balanced Accuracy
        # = 0.5 * (TP/(TP+FN) + TN/(TN+FP))
        sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0
        specificity = TN / (TN + FP) if (TN + FP) != 0 else 0
        b_acc = 0.5 * (sensitivity + specificity)

        # Precision, Recall, F1
        precision = precision_score(self.true_labels, self.final_decisions, zero_division=0)
        recall = recall_score(self.true_labels, self.final_decisions, zero_division=0)
        f1 = f1_score(self.true_labels, self.final_decisions, zero_division=0)

        # AUC
        auc_val = None
        if self.probabilities_test is not None:
            # Ø§Ú¯Ø± probabilities_test Ø®Ø±ÙˆØ¬ÛŒ predict_proba (Ø³ØªÙˆÙ† Ú©Ù„Ø§Ø³ Û±) Ø¨Ø§Ø´Ø¯:
            try:
                auc_val = roc_auc_score(self.true_labels, self.probabilities_test)
            except Exception:
                auc_val = None

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ…ØŒ Ø¯Ø± ØµÙˆØ±ØªÛŒ Ú©Ù‡ cost_matrix Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´ÛŒÙ…
        # ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ cost_matrix[i] = {"PP", "PN", "NP", "NN"}
        # Ùˆ final_decisions[i] = 1 => POS, 0 => NEG
        # true_labels[i] = 1 => Ù†Ù…ÙˆÙ†Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ Ù†Ú©ÙˆÙ„, 0 => ØºÛŒØ±Ù†Ú©ÙˆÙ„
        total_cost = None
        if self.cost_matrix is not None:
            if len(self.cost_matrix) != len(self.true_labels):
                logging.warning("Ø·ÙˆÙ„ cost_matrix Ø¨Ø§ Ø¯Ø§Ø¯Ù‡Ù” ØªØ³Øª Ù‡Ù…Ø®ÙˆØ§Ù†ÛŒ Ù†Ø¯Ø§Ø±Ø¯Ø› Ù‡Ø²ÛŒÙ†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            else:
                total_cost_calc = 0.0
                for i in range(len(self.true_labels)):
                    y_true = self.true_labels[i]
                    y_pred = self.final_decisions[i]
                    costs = self.cost_matrix[i]
                    # Ø§Ú¯Ø± y_pred=1 Ùˆ y_true=1 => PP
                    # Ø§Ú¯Ø± y_pred=1 Ùˆ y_true=0 => PN
                    # Ø§Ú¯Ø± y_pred=0 Ùˆ y_true=1 => NP
                    # Ø§Ú¯Ø± y_pred=0 Ùˆ y_true=0 => NN
                    if y_pred == 1 and y_true == 1:
                        total_cost_calc += costs["PP"]
                    elif y_pred == 1 and y_true == 0:
                        total_cost_calc += costs["PN"]
                    elif y_pred == 0 and y_true == 1:
                        total_cost_calc += costs["NP"]
                    elif y_pred == 0 and y_true == 0:
                        total_cost_calc += costs["NN"]
                total_cost = total_cost_calc

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ GM Ø¨Ù‡ ØµÙˆØ±Øª sqrt((TP/(TP+FN)) * (TN/(TN+FP)))
        gm = np.sqrt((TP / (TP + FN)) * (TN / (TN + FP))) if (TP + FN) != 0 and (TN + FP) != 0 else 0

        metrics_dict = {"ModelName": "Proposed-3WD", "TN": TN, "FP": FP, "FN": FN, "TP": TP, "BalancedAccuracy": b_acc,
            "Precision": precision, "Recall": recall, "F1": f1, "GM": gm, "AUC": auc_val, "TotalCost": total_cost}
        return metrics_dict


from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
from math import sqrt
import logging


class ParsianMethodComparison:
    """
    Ø¯Ø± Ø§ÛŒÙ† Ú¯Ø§Ù…ØŒ Ù…Ø¬Ù…ÙˆØ¹Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ù‚ÛŒØ¨ (Baseline) Ø±Ø§ Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
    Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ Ø³Ù¾Ø³ Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ø¨Ø§ Ø±ÙˆØ´ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ
    (Ø³Ù‡â€ŒØ·Ø±ÙÙ‡) Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø´ÙˆÙ†Ø¯.

    Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ:
      - TP, TN, FP, FN Ø§Ø² Ù…Ø§ØªØ±ÛŒØ³ Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ
      - BalancedAccuracy = 0.5 * (TP/(TP+FN) + TN/(TN+FP))
      - Precision, Recall, F1 (ÛŒØ§ FM Ø¨Ø§ Î²=1)
      - GM = sqrt( (TP/(TP+FN)) * (TN/(TN+FP)) )
      - AUC (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ø§Ø­ØªÙ…Ø§Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ)
      - TotalCost (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ cost_matrix)
    """

    def __init__(self, x_train: pd.DataFrame, y_train: pd.Series, x_test: pd.DataFrame, y_test: pd.Series,
            cost_matrix: list = None, model_comparisons: dict = None):
        """
        Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§:
         - x_train, y_train: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´
         - x_test, y_test: Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª
         - cost_matrix: Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ… (Ù…Ø§Ù†Ù†Ø¯ Ú¯Ø§Ù… Û³)
         - model_comparisons: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ { ModelName: model_object } Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ù‚ÛŒØ¨
        """
        self.x_train = x_train
        self.y_train = y_train
        self.x_test = x_test
        self.y_test = y_test
        self.cost_matrix = cost_matrix

        if model_comparisons is None:
            from sklearn.naive_bayes import GaussianNB
            from sklearn.neighbors import KNeighborsClassifier
            from sklearn.linear_model import LogisticRegression
            from sklearn.neural_network import MLPClassifier
            from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, \
                RandomForestClassifier, BaggingClassifier
            from lightgbm import LGBMClassifier
            from xgboost import XGBClassifier
            from sklearn.ensemble import StackingClassifier
            from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

            self.model_comparisons = {"Bayes": GaussianNB(), "KNN": KNeighborsClassifier(),
                "LR": LogisticRegression(max_iter=10_000), "NN": MLPClassifier(max_iter=300),
                "AdaBoost": AdaBoostClassifier(algorithm="SAMME"), "ERT": ExtraTreesClassifier(),
                "GBDT": GradientBoostingClassifier(), "LGBM": LGBMClassifier(verbose=-1),
                "RF": RandomForestClassifier(), "XGB": XGBClassifier(eval_metric='logloss', verbosity=0),
                "Stacking": StackingClassifier(
                    estimators=[('lda', LinearDiscriminantAnalysis()), ('knn', KNeighborsClassifier())],
                    final_estimator=RandomForestClassifier()),
                "Bagging": BaggingClassifier(estimator=ExtraTreesClassifier(n_estimators=100, random_state=42),
                    n_estimators=10, random_state=42)}
        else:
            self.model_comparisons = model_comparisons

        self.comparison_table = None

    def _compute_metrics(self, y_true, y_pred, y_prob=None, cost_matrix=None):
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯: TP, TN, FP, FN, BalancedAccuracy, Precision, Recall, F1, GM, AUC Ùˆ TotalCost.
        """
        cm = confusion_matrix(y_true, y_pred)
        TN, FP, FN, TP = cm.ravel()

        # Balanced Accuracy
        b_acc = 0.5 * ((TP / (TP + FN) if (TP + FN) > 0 else 0) + (TN / (TN + FP) if (TN + FP) > 0 else 0))

        # Precision Ùˆ Recall
        precision = precision_score(y_true, y_pred, zero_division=0)
        recall = recall_score(y_true, y_pred, zero_division=0)

        # F1 (Ú©Ù‡ Ù‡Ù…Ø§Ù† FM Ø¨Ø§ Î²=1 Ø§Ø³Øª)
        f1 = f1_score(y_true, y_pred, zero_division=0)

        # GM
        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0
        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0
        gm = sqrt(sensitivity * specificity)

        # AUC
        auc_val = None
        if y_prob is not None:
            from sklearn.metrics import roc_auc_score
            try:
                auc_val = roc_auc_score(y_true, y_prob)
            except Exception:
                auc_val = None

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡ ØªØµÙ…ÛŒÙ… (TotalCost)
        total_cost = None
        if cost_matrix is not None and len(cost_matrix) == len(y_true):
            tc = 0.0
            for i in range(len(y_true)):
                yi = y_true[i]
                yp = y_pred[i]
                costs = cost_matrix[i]
                if yi == 1 and yp == 1:
                    tc += costs["PP"]
                elif yi == 0 and yp == 1:
                    tc += costs["PN"]
                elif yi == 1 and yp == 0:
                    tc += costs["NP"]
                elif yi == 0 and yp == 0:
                    tc += costs["NN"]
            total_cost = tc

        return {"TP": TP, "TN": TN, "FP": FP, "FN": FN, "BalancedAccuracy": b_acc, "Precision": precision,
            "Recall": recall, "F1": f1, "GM": gm, "AUC": auc_val, "TotalCost": total_cost}

    def run_comparison(self):
        """
        Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø¯Ù„ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ù‚ÛŒØ¨:
          - Ø¢Ù…ÙˆØ²Ø´ Ø±ÙˆÛŒ x_train, y_train
          - Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ x_test (y_pred Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù† y_prob)
          - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
          - Ø«Ø¨Øª Ù†ØªØ§ÛŒØ¬ Ø¯Ø± ÛŒÚ© DataFrame
        Ø®Ø±ÙˆØ¬ÛŒ: DataFrame Ø´Ø§Ù…Ù„ Ù†ØªØ§ÛŒØ¬ Ù…Ù‚Ø§ÛŒØ³Ù‡
        """
        logging.info("ğŸ”µ Ø´Ø±ÙˆØ¹ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø³Ø§ÛŒØ± Ø±ÙˆØ´â€ŒÙ‡Ø§ (Ú¯Ø§Ù… Û¹) ...")
        results_list = []
        for model_name, model_obj in self.model_comparisons.items():
            model_obj.fit(self.x_train, self.y_train)

            y_pred = model_obj.predict(self.x_test)

            y_prob = None
            try:
                prob_mat = model_obj.predict_proba(self.x_test)
                y_prob = prob_mat[:, 1]
            except Exception:
                y_prob = None

            metrics = self._compute_metrics(y_true=self.y_test.values, y_pred=y_pred, y_prob=y_prob,
                cost_matrix=self.cost_matrix)
            metrics["ModelName"] = model_name
            results_list.append(metrics)

        df_results = pd.DataFrame(results_list)
        df_results.sort_values(by="BalancedAccuracy", ascending=False, inplace=True)
        self.comparison_table = df_results.reset_index(drop=True)
        logging.info("âœ… Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ù‚ÛŒØ¨ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª.")
        return self.comparison_table

    def add_proposed_method_results(self, proposed_method_metrics: dict):
        """
        Ø§ÙØ²ÙˆØ¯Ù† Ù†ØªØ§ÛŒØ¬ Ø±ÙˆØ´ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡.
        proposed_method_metrics Ø¨Ø§ÛŒØ¯ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ:
        ModelName, TP, TN, FP, FN, BalancedAccuracy, Precision, Recall, F1, GM, AUC, TotalCost
        Ø¨Ø§Ø´Ø¯.
        """
        self.comparison_table = pd.concat([self.comparison_table, pd.DataFrame([proposed_method_metrics])],
            ignore_index=True)
        self.comparison_table.sort_values(by="BalancedAccuracy", ascending=False, inplace=True)
        self.comparison_table.reset_index(drop=True, inplace=True)
        logging.info("ğŸ”µ Ù†ØªØ§ÛŒØ¬ Ø±ÙˆØ´ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ù‡Ù… Ø¨Ù‡ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯.")

    def show_final_comparison(self):
        """
        Ù†Ù…Ø§ÛŒØ´ Ø¬Ø¯ÙˆÙ„ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ø± Ù„Ø§Ú¯ Ùˆ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¢Ù†.
        ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§Ù†Ø¯Ø§Ø² Ø¨Ù‡ Ú¯ÙˆÙ†Ù‡â€ŒØ§ÛŒ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù‡Ù…Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† ellipsis Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´ÙˆÙ†Ø¯.
        """
        logging.info("ğŸ”¸ Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§:")
        logging.warning("\n" + str(self.comparison_table))
        return self.comparison_table


###########################################
# ØªØ³Øª Ú©Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§ÛŒÙ† ÙØ§ÛŒÙ„)
###########################################
if __name__ == "__main__":
    os.environ["LOKY_MAX_CPU_COUNT"] = "8"

    logging.basicConfig(level=logging.INFO)

    # Ø³Ø§Ø®Øª Ø¢Ø¨Ø¬Ú©Øª Ù…Ø®Ø²Ù† Ø¯Ø§Ø¯Ù‡ (LoanRepository)
    repo = LoanRepository()

    # Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ (ParsianPreprocessingManager)
    prep_manager = ParsianPreprocessingManager(repository=repo, limit_records=5000, label_column="status",
        imputation_strategy="mean", need_2_remove_highly_correlated_features=False, correlation_threshold=0.9,
        do_balance=True, test_size=0.2, random_state=42)

    x_train, y_train, x_test, y_test, original_df = prep_manager.step1_process_data()
    if x_train is None:
        logging.error("Ú¯Ø§Ù… Ø§ÙˆÙ„ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
        exit(1)

    # 2) Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø§Ù… Ø¯ÙˆÙ…: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„
    default_model = ParsianDefaultProbabilityModel(model_type="lightgbm", n_estimators=100, learning_rate=0.05,
        random_state=42)
    default_model.fit_model(x_train, y_train)
    probabilities_test = default_model.predict_default_probability(x_test)

    visualizer = Plot()
    visualizer.visualize_distribution(probabilities_test)

    logging.info(f"Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ† 5 Ù†Ù…ÙˆÙ†Ù‡: {probabilities_test[:5]}")
    logging.info("Ú¯Ø§Ù… Ø¯ÙˆÙ… (Ø¨Ø±Ø¢ÙˆØ±Ø¯ Ø§Ø­ØªÙ…Ø§Ù„ Ù†Ú©ÙˆÙ„) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    # 3) Ú¯Ø§Ù… Ø³ÙˆÙ…: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø§ØªØ±ÛŒØ³ Ø²ÛŒØ§Ù†
    # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… x_test Ø¯Ø§Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ approval_amount Ùˆ interest_amount Ø§Ø³Øª.
    cost_calc = ParsianCostMatrix(df_test=x_test, approval_col="approval_amount", interest_col="interest_amount")
    cost_calc.compute_costs()
    all_costs = cost_calc.get_all_costs()

    # 4) Ú¯Ø§Ù… Ú†Ù‡Ø§Ø±Ù…: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú†Ù†Ø¯Ù‡Ø¯ÙÙ‡ Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ NSGA-II
    from numpy import array

    threshold_nsgaii = ParsianThresholdNSGA2(probabilities_test=probabilities_test, cost_matrix=all_costs,
        true_labels=y_test.values,  # ÛŒØ§ array(y_test)
        pop_size=50, n_gen=100, step_bnd=False)
    threshold_nsgaii.optimize()

    solutions, objectives = threshold_nsgaii.get_pareto_front()
    logging.info("ğŸ”¹ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±ØªÙˆ (alpha,beta) Ùˆ Ù…Ù‚Ø¯Ø§Ø± Ø§Ù‡Ø¯Ø§Ù (cost,boundary):")
    for i, sol in enumerate(solutions):
        alpha, beta = sol
        cost_val, boundary_val = objectives[i]
        logging.info(f"  alpha={alpha:.3f}, beta={beta:.3f} => cost={cost_val:.2f}, boundary={boundary_val:.3f}")

    # Ø§Ù†ØªØ®Ø§Ø¨ Ø±Ø§Ù‡â€ŒØ­Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø² Ù…ÛŒØ§Ù† Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø±ØªÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù…ØªØ±ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± objective Ø¯ÙˆÙ… (boundary_size)
    final_solution, final_objectives = threshold_nsgaii.get_final_solution()
    best_alpha, best_beta = final_solution[0], final_solution[1]
    logging.warning(
        f"ğŸ”¹ the best is: alpha={best_alpha:.3f}, beta={best_beta:.3f} => cost={final_objectives[0]:.2f}, boundary={final_objectives[1]:.3f}")
    logging.info("Ú¯Ø§Ù… Ú†Ù‡Ø§Ø±Ù… (NSGA-II Ú†Ù†Ø¯Ù‡Ø¯ÙÙ‡) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    threeway = ParsianThreeWayDecision(probabilities_test, best_alpha, best_beta)
    decisions_final = threeway.apply_three_way_decision()
    logging.info(f"Decision counts: POS: {threeway.get_decision_counts().get(1, 0)} samples,"
                 f" NEG: {threeway.get_decision_counts().get(0, 0)} samples,"
                 f" BND: {threeway.get_decision_counts().get(-1, 0)} samples")

    # 6) Ú¯Ø§Ù… Ø´Ø´Ù…: ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆÛŒ BNDÙ‡Ø§
    bnd_resolver = ParsianBNDResolver(x_train_all=x_train, y_train_all=y_train, model_type="stacking")
    bnd_resolver.fit_bnd_model()

    # Ø§Ø¹Ù…Ø§Ù„ Ù…Ø¯Ù„ Ø§Ø³ØªÚ©ÛŒÙ†Ú¯ Ø±ÙˆÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø²ÛŒ
    decisions_updated = bnd_resolver.resolve_bnd_samples(x_test, decisions_final)

    logging.info("ğŸ”¹ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø³ Ø§Ø² Ú¯Ø§Ù… Ø´Ø´Ù…:")
    logging.info(
        f" count POS={np.sum(decisions_updated == 1)}, NEG={np.sum(decisions_updated == 0)}, BND={np.sum(decisions_updated == -1)}")

    # 7) Ú¯Ø§Ù… Ù‡ÙØªÙ…: Evaluation Ù†Ù‡Ø§ÛŒÛŒ
    final_eval = ParsianFinalEvaluator(true_labels=y_test.values, final_decisions=decisions_updated,
        probabilities_test=probabilities_test,  # Ø§Ú¯Ø± AUC Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ…
        cost_matrix=all_costs  # Ø§Ú¯Ø± Ù‡Ø²ÛŒÙ†Ù‡ Ø¨Ø®ÙˆØ§Ù‡ÛŒÙ…
    )
    results = final_eval.evaluate_metrics()
    logging.info("ğŸ”¹ Ù†ØªØ§ÛŒØ¬ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„:")
    for k, v in results.items():
        logging.info(f"  {k}: {v}")

    comparator = ParsianMethodComparison(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test,
        cost_matrix=all_costs,  # Ø§Ú¯Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ù‡Ø²ÛŒÙ†Ù‡ Ù‡Ù… Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´ÙˆØ¯
        model_comparisons=None  # Ø§Ú¯Ø± None Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯ØŒ Ú†Ù†Ø¯ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¯Ø§Ø±Ø¯
    )
    comparison_df = comparator.run_comparison()
    logging.error("\nÙ†ØªØ§ÛŒØ¬ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø±Ù‚ÛŒØ¨:\n" + str(comparison_df))

    comparator.add_proposed_method_results(proposed_method_metrics=results)

    final_comparison = comparator.show_final_comparison()
    logging.info("ğŸ”¹ Ú¯Ø§Ù… Ù†Ù‡Ù… (Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø³Ø§ÛŒØ± Ø±ÙˆØ´â€ŒÙ‡Ø§) Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
